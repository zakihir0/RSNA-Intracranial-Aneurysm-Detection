{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"},{"sourceId":266589125,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# RSNA Intracranial Aneurysm - Single-Page Script (Complete)\n# ---------------------------------------------------------------\n# 改善点:\n# 1) Cosine+Warmup LR (+EMA)\n# 2) 入力解像度384 + Mixed Precision (AMP) + LearnableRGB(Conv1x1)\n# 3) クラス別しきい値最適化（Youden J; 提出時は通常OFF）\n#\n# 保存/読込:\n# - 学習時(SUBMISSIONING=False)は /kaggle/working/rsna-2xx/rsna_2_10_0.h5 に保存\n# - 読込は /kaggle/working → /kaggle/input の順で探索\n#\n# 依存:\n# - Kaggle 環境を想定（RSNAコンペ入出力構成）\n# - 外部DLが困難な環境に備え、EfficientNetV2のweightsは既定でNone（=DLしない）\n\nimport os\nimport math\nimport shutil\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nimport tensorflow as tf\nimport keras_tuner as kt\nimport pydicom\nimport kaggle_evaluation.rsna_inference_server\n\n\n\n\n# ============================\n# 0) 環境/パス設定\n# ============================\n# ここを False にすると学習→ /kaggle/working に保存します\nSUBMISSIONING = True\n\n# モデル保存/読込パス\nMODEL_DIR_WORK = \"/kaggle/working/rsna-2xx\"\nMODEL_DIR_INPUT = \"/kaggle/input/rsna-transfer-learning-efficientnet-image-aug/rsna-2xx\"\nMODEL_NAME = \"rsna_2_10_0.h5\"\nMODEL_PATH_WORK = os.path.join(MODEL_DIR_WORK, MODEL_NAME)\nMODEL_PATH_INPUT = os.path.join(MODEL_DIR_INPUT, MODEL_NAME)\nos.makedirs(MODEL_DIR_WORK, exist_ok=True)\n\n# オフライン安全: ImageNet重みDLを避ける（必要なら環境変数で上書き）\nUSE_IMAGENET = os.getenv(\"USE_IMAGENET\", \"0\") in (\"1\", \"true\", \"True\")\nLOCAL_WEIGHTS = os.getenv(\"LOCAL_WEIGHTS\", \"\")  # ベースCNNのローカル重みがある場合\n\n# Mixed Precision\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu='local')\n    print('✅ Running on TPU ', tpu.master())\nexcept Exception:\n    print('❌ Using CPU/GPU')\n    tpu = None\n\nif tpu:\n    strategy = tf.distribute.TPUStrategy(tpu)\n    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\nelse:\n    strategy = tf.distribute.get_strategy()\n    try:\n        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n    except Exception:\n        pass\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# ============================\n# 1) データ読み込みと分割\n# ============================\npath = '/kaggle/input/rsna-intracranial-aneurysm-detection/'\ntrainval = pd.read_csv(os.path.join(path, \"train.csv\"))\ntrainval_localizers = pd.read_csv(os.path.join(path, \"train_localizers.csv\"))\ntrainval = trainval.merge(trainval_localizers, on='SeriesInstanceUID', how='outer')\n\n# StratifiedGroupKFold 用クラス作成（多ラベル→多クラス）\nlabel_columns = trainval.columns[trainval.columns.str.contains('Artery|Tip|Other|Present', case=True)]\nlabel2class = {}\ntrainval['class'] = 0\nfor i, col in enumerate(label_columns[:]):\n    label2class[col] = i + 1\n    if i < 13:\n        trainval['class'] = trainval['class'] + trainval[col] * (i + 1)\n\nskf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=33)\nfor fold, (train_idx, val_idx) in enumerate(\n    skf.split(trainval, y=trainval['class'], groups=trainval['SeriesInstanceUID'])\n):\n    train = trainval.iloc[train_idx].reset_index(drop=True)\n    val   = trainval.iloc[val_idx].reset_index(drop=True)\n    print(f\"✅ Fold {fold}: Train size = {len(train_idx)}, Val size = {len(val_idx)}\")\n    break\n\n# ============================\n# 2) 画像前処理\n# ============================\nimage_size = 384  # 改善点(2): 解像度UP\n\ndef crop_image(image, x, y, tol=0.05, crop=True):\n    img = image[0, :, :, 0]\n    mask = img > tol\n    if crop and mask.sum() > 1000:\n        masked_idx = np.ix_(mask.any(1), mask.any(0))\n        image = img[masked_idx]\n        image = image.reshape(1, image.shape[0], image.shape[1], 1)\n    if crop and x >= 0 and mask.sum() > 1000:\n        coor = np.zeros((img.shape), dtype=float)\n        coor[round(y), round(x)] = 1\n        coor_masked = coor[masked_idx]\n        row, col = np.where(coor_masked == 1)\n        y, x = row[0], col[0]\n    return image, x, y\n\ndef pad_and_resize(image, x, y):\n    _, h, w, _ = image.shape\n    pad_size = max(h, w)\n    image_padded = tf.image.resize_with_crop_or_pad(image, pad_size, pad_size)\n    image_resized = tf.image.resize(image_padded, [image_size, image_size], method=tf.image.ResizeMethod.BICUBIC)\n    if x >= 0:\n        coor = np.zeros((image.shape), dtype=float)\n        coor[:, round(y), round(x), :] = 1\n        coor_padded = tf.image.resize_with_crop_or_pad(coor, pad_size, pad_size)\n        coor_resized = tf.image.resize(coor_padded, [image_size, image_size], method=tf.image.ResizeMethod.AREA)\n        _, row, col, _ = np.where(coor_resized.numpy() == coor_resized.numpy().max())\n        y, x = row[0], col[0]\n    return image_resized, x, y\n\ndef image_augmentation(image, x, y, augmentation=True):\n    if augmentation:\n        coor = np.zeros((image.shape), dtype=float)\n        zoom_fac = np.random.uniform(0.0, 0.0)\n        rot_fac = np.random.uniform(-0.1, 0.1)\n        trans_fac = np.random.uniform(-0.05, 0.05)\n        z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(image)\n        z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n        image = tf.keras.layers.RandomTranslation(\n            height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n            interpolation='nearest', fill_mode='constant', name='auglay3'\n        )(z)\n        if x >= 0:\n            coor[:, round(y), round(x), :] = 1\n            coor = tf.convert_to_tensor(coor)\n            z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(coor)\n            z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n            coor = tf.keras.layers.RandomTranslation(\n                height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n                interpolation='nearest', fill_mode='constant', name='auglay3'\n            )(z)\n            _, row, col, _ = np.where(coor.numpy() == coor.numpy().max())\n            y, x = row[0], col[0]\n    return image, x, y\n\ndef preprocess_images(image, x, y, crop, augmentation):\n    image_scaled = (MinMaxScaler().fit_transform(image.reshape(-1, 1))).reshape(1, image.shape[0], image.shape[1], 1).astype(np.float32)\n    try:\n        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=crop)\n    except Exception:\n        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=False)\n    image_aug, x_a, y_a = image_augmentation(image_c, x_c, y_c, augmentation=augmentation)\n    image_resized, x_r, y_r = pad_and_resize(image_aug, x_a, y_a)\n    image_resized = tf.cast(image_resized*255, dtype=tf.uint8)\n    if x >= 0:\n        x_rs, y_rs = x_r/image_size, y_r/image_size\n    else:\n        x_rs, y_rs = -1, -1\n    return image_resized, x_rs, y_rs\n\n# ============================\n# 3) データセット作成\n# ============================\niteration_nr = 4\nroot_path = os.path.join(path, 'series')\nencoder_mod = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit([['MR'], ['CT']])\n\ndef preprocess_step(data, iter_nr):\n    image_list, modality_list, label_list, coordinates_list = [], [], [], []\n    for i, idx in enumerate(tqdm(data.index)):\n        data_slice = data.loc[idx]\n        subfolder = data_slice['SeriesInstanceUID']\n        subfolder_path = os.path.join(root_path, subfolder)\n\n        files_in = os.listdir(subfolder_path)\n        files_in.sort()\n        if len(files_in) > iter_nr:\n            file_name = files_in[iter_nr]\n        else:\n            file_name = files_in[-1]\n        if not pd.isna(data_slice.get('SOPInstanceUID')):\n            file_name = f\"{data_slice['SOPInstanceUID']}.dcm\"\n\n        dcm = pydicom.dcmread(os.path.join(subfolder_path, file_name))\n        try:\n            nr_frames = int(dcm.NumberOfFrames)\n            if data_slice['Aneurysm Present'] == 1:\n                frame_nr = int(eval(data_slice['coordinates'])['f'])\n            else:\n                frame_nr = min(iter_nr, nr_frames-1)\n        except Exception:\n            frame_nr = 0\n\n        # フレーム取得\n        img = getattr(pydicom, 'pixels', None)\n        if img and hasattr(pydicom, 'pixels'):\n            image = pydicom.pixels.pixel_array(dcm, index=frame_nr)\n        else:\n            image = dcm.pixel_array\n\n        mod = encoder_mod.transform([[dcm.Modality]])\n        if pd.isna(data_slice.get('coordinates')):\n            x, y = -1, -1\n        else:\n            xy = eval(data_slice['coordinates'])\n            x, y = xy['x'], xy['y']\n\n        image_resized, x_rs, y_rs = preprocess_images(\n            image, x, y, crop=False, augmentation=(iter_nr > 0 and data_slice['Aneurysm Present'] == 1)\n        )\n        coordinates_tensor = tf.expand_dims(tf.convert_to_tensor([x_rs, y_rs], dtype=np.float32), 0)\n        image_list.append(image_resized)\n        modality_list.append(mod)\n        coordinates_list.append(coordinates_tensor)\n\n        labels = data_slice[label_columns]\n        label_tensor = tf.expand_dims(tf.convert_to_tensor(labels, dtype=np.float32), 0)\n        label_list.append(label_tensor)\n\n    images = tf.concat(image_list, axis=0)\n    modalities = tf.concat(modality_list, axis=0)\n    labels = tf.concat(label_list, axis=0)\n    coordinates = tf.concat(coordinates_list, axis=0)\n    return images, labels, coordinates, modalities\n\ndef preprocess_loop(data, iteration_nr):\n    data_images_list, data_modalities_list, data_labels_list, data_coordinates_list = [], [], [], []\n    for i in range(iter_nr := iteration_nr):\n        di, dl, dc, dm = preprocess_step(data, i)\n        data_images_list.append(di)\n        data_modalities_list.append(dm)\n        data_labels_list.append(dl)\n        data_coordinates_list.append(dc)\n    data_images = tf.concat(data_images_list, axis=0)\n    data_modalities = tf.concat(data_modalities_list, axis=0)\n    data_labels = tf.concat(data_labels_list, axis=0)\n    data_coordinates = tf.concat(data_coordinates_list, axis=0)\n    return data_images, data_labels, data_coordinates, data_modalities\n\nif not SUBMISSIONING:\n    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:], iteration_nr)\n    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:], iteration_nr)\nelse:\n    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:64], iteration_nr)\n    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:64], iteration_nr)\n\nSEED = 42\nbatch_size = 32 if image_size >= 384 else 64\nbatch_size_val = batch_size\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    ({\"input_img\": train_images, \"input_mod\": train_modalities},\n     {\"class\": train_labels, \"reg\": train_coordinates})\n).shuffle(len(train_labels), seed=SEED).repeat().batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\nval_ds = tf.data.Dataset.from_tensor_slices(\n    ({\"input_img\": val_images, \"input_mod\": val_modalities},\n     {\"class\": val_labels, \"reg\": val_coordinates})\n).batch(batch_size_val, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n\n# ============================\n# 4) モデル定義\n# ============================\nlabel_weights = tf.constant([1,1,1,1,1,1,1,1,1,1,1,1,1,13], dtype=tf.float32)/26\n\n@tf.keras.utils.register_keras_serializable()\nclass WeightedBinaryCrossentropy(tf.keras.losses.Loss):\n    def __init__(self, name=\"weighted_bce_loss\", reduction='sum_over_batch_size'):\n        super().__init__(name=name, reduction=reduction)\n        self.weight_positive = 1 - tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n        self.weight_negative = tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n        self.label_weights = label_weights\n    def call(self, y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n        bce = -(self.weight_positive * y_true * tf.math.log(y_pred) +\n                self.weight_negative * (1 - y_true) * tf.math.log(1 - y_pred))\n        bce = bce * self.label_weights\n        return tf.reduce_mean(bce)\n\n@tf.keras.utils.register_keras_serializable()\nclass LearnableRGB(tf.keras.layers.Layer):\n    def __init__(self, **kwargs): super().__init__(**kwargs)\n    def build(self, input_shape):\n        self.conv = tf.keras.layers.Conv2D(3, 1, use_bias=False, name=\"rgb_1x1\")\n    def call(self, x):\n        x = tf.cast(x, tf.float32)/255.0\n        return self.conv(x)\n\n@tf.keras.utils.register_keras_serializable()\nclass PreProcess(tf.keras.layers.Layer):\n    def __init__(self, base_network_type, **kwargs):\n        super().__init__(**kwargs)\n        if base_network_type < 9:\n            self.preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n        else:\n            self.preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n    def call(self, inputs):\n        x = tf.cast(inputs, tf.float32)\n        return self.preprocess_input(x*255.0)\n\ndef _build_base_model(image_size, base_network_type=9):\n    # オフライン安全: まずローカル重み→ImageNet許可→Noneの順\n    weights_arg = 'imagenet' if USE_IMAGENET else None\n    def _make(weights):\n        return tf.keras.applications.EfficientNetV2B0(\n            include_top=False, input_shape=[image_size, image_size, 3], weights=weights\n        )\n    try:\n        if LOCAL_WEIGHTS and os.path.exists(LOCAL_WEIGHTS):\n            print(f\"Loading base model w/ local weights: {LOCAL_WEIGHTS}\")\n            m = _make(None)\n            m.load_weights(LOCAL_WEIGHTS, by_name=True, skip_mismatch=True)\n            return m\n        else:\n            try:\n                m = _make(weights_arg)  # ここでDLが必要なら、USE_IMAGENET=Falseで回避\n                return m\n            except Exception as e:\n                print(f\"[WARN] Pretrained weights not available ({e}). Using random init.\")\n                return _make(None)\n    except Exception as e:\n        print(f\"[WARN] Base model fallback to random init ({e}).\")\n        return _make(None)\n\ndef build_network(hp):\n    base_network_type = 9  # EfficientNetV2B0\n    base_model = _build_base_model(image_size, base_network_type)\n    preprocessing = PreProcess(base_network_type=base_network_type, name='preprocessing')\n    base_model.trainable = True\n\n    # 入力\n    input_img = tf.keras.Input(shape=(image_size, image_size, 1), name='input_img')\n    input_mod = tf.keras.Input(shape=(2,), name='input_mod')\n\n    # 前処理・ベース\n    x = LearnableRGB(name='learnable_rgb')(input_img)\n    x = preprocessing(x)\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D(name='gap2d')(x)\n    x = tf.keras.layers.BatchNormalization(name='gap2d_bn')(x)\n    x = tf.keras.layers.Dropout(0.1, name='gap2d_do')(x)\n\n    # モダリティ結合\n    x = tf.keras.layers.Concatenate(name='concat_gap')([x, input_mod])\n\n    # 分類ヘッド\n    y = tf.keras.layers.Dense(512, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc1')(x)\n    y = tf.keras.layers.BatchNormalization(name='final_bn1')(y)\n    y = tf.keras.layers.Dropout(0.1, name='final_do1')(y)\n    output_lab = tf.keras.layers.Dense(len(label2class.keys()), activation=\"sigmoid\", name='class', dtype='float32')(y)\n\n    # 回帰ヘッド\n    z = tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc_reg1')(x)\n    z = tf.keras.layers.Dropout(0.1, name='final_do_reg1')(z)\n    output_coord = tf.keras.layers.Dense(2, activation=\"linear\", name='reg', dtype='float32')(z)\n\n    model = tf.keras.Model(inputs=[input_img, input_mod], outputs=[output_lab, output_coord], name='RSNA_Class')\n\n    optimizer = tf.keras.optimizers.Adam(1e-3)\n    loss_class = WeightedBinaryCrossentropy()\n    loss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\n    loss_weights = {\"reg\": 0.01, \"class\": 0.99}\n    auc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='auc')\n    metrics = {\"reg\": [\"mae\"], \"class\": [auc]}\n    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n    return model\n\n# ============================\n# 5) LR: Cosine+Warmup / EMA\n# ============================\nwarmup_epochs = 5\ntotal_epochs  = 100\nbase_lr = 1e-3\nmin_lr  = 1e-5\n\ndef cosine_warmup_lr(epoch):\n    if epoch < warmup_epochs:\n        return base_lr * (epoch + 1) / warmup_epochs\n    t = (epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n    return float(min_lr + 0.5*(base_lr - min_lr)*(1 + math.cos(math.pi*t)))\n\nlr_cb = tf.keras.callbacks.LearningRateScheduler(cosine_warmup_lr, verbose=0)\n\nclass EMAWeights(tf.keras.callbacks.Callback):\n    def __init__(self, model, decay=0.999):\n        super().__init__()\n        self.decay = decay\n        self.shadow = [w.numpy() for w in model.weights]\n        self.model_ref = model\n    def on_train_batch_end(self, batch, logs=None):\n        for i, w in enumerate(self.model_ref.weights):\n            self.shadow[i] = self.decay*self.shadow[i] + (1.0 - self.decay)*w.numpy()\n    def on_train_end(self, logs=None):\n        for var, swa in zip(self.model_ref.weights, self.shadow):\n            var.assign(swa)\n\n# ============================\n# 6) モデルのロード/ビルド\n# ============================\ndef load_or_build_model():\n    custom = {\n        \"WeightedBinaryCrossentropy\": WeightedBinaryCrossentropy,\n        \"LearnableRGB\": LearnableRGB,\n        \"PreProcess\": PreProcess,\n    }\n    # 1) /kaggle/working を優先\n    if os.path.exists(MODEL_PATH_WORK):\n        try:\n            m = tf.keras.models.load_model(MODEL_PATH_WORK, custom_objects=custom, compile=False)\n            print(f\"Loaded model from WORKING: {MODEL_PATH_WORK}\")\n            return m\n        except Exception as e:\n            print(f\"[WARN] Failed to load WORKING model: {e}\")\n    # 2) 次に /kaggle/input\n    if os.path.exists(MODEL_PATH_INPUT):\n        try:\n            m = tf.keras.models.load_model(MODEL_PATH_INPUT, custom_objects=custom, compile=False)\n            print(f\"Loaded model from INPUT: {MODEL_PATH_INPUT}\")\n            return m\n        except Exception as e:\n            print(f\"[WARN] Failed to load INPUT model: {e}\")\n    # 3) 無ければ新規構築\n    print(\"No saved model found. Building a fresh model.\")\n    with strategy.scope():\n        return build_network(kt.HyperParameters())\n\nmodel = load_or_build_model()\n\n# 再コンパイル（load_model時は compile=False のため）\noptimizer = tf.keras.optimizers.Adam(1e-3)\nloss_class = WeightedBinaryCrossentropy()\nloss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\nloss_weights = {\"reg\": 0.01, \"class\": 0.99}\nauc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='auc')\nmetrics = {\"reg\": [\"mae\"], \"class\": [auc]}\nmodel.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n\n# ============================\n# 7) 学習\n# ============================\nepochs = total_epochs\nsteps_per_epoch = max(1, len(train)//batch_size)\nTRAINING = (not SUBMISSIONING)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    patience=15, monitor='val_class_auc', mode='max', restore_best_weights=True\n)\nema_cb = EMAWeights(model, decay=0.999)\n\nif TRAINING:\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=epochs,\n        steps_per_epoch=steps_per_epoch,\n        callbacks=[lr_cb, early_stopping_cb, ema_cb],\n        verbose=1\n    )\n    # /kaggle/working に保存（ご要望どおり）\n    model.save(MODEL_PATH_WORK, include_optimizer=False)\n    print(f\"Model weights have been saved to: {MODEL_PATH_WORK}\")\n\n# ============================\n# 8) しきい値最適化（任意）\n# ============================\nTHRESH_FILE = os.path.join(MODEL_DIR_WORK, 'class_thresholds.npy')\nAPPLY_THRESHOLDS = False  # 競技が確率提出なら False のまま\n\ndef compute_optimal_thresholds(model, val_images, val_modalities, val_labels, num_points=201):\n    probs, _ = model.predict((val_images, val_modalities), verbose=0)\n    probs = np.asarray(probs)  # (N, C)\n    labels = np.asarray(val_labels)  # (N, C)\n    C = probs.shape[1]\n    thresholds = np.zeros(C, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, num_points)\n    for c in range(C):\n        y_true = labels[:, c].astype(np.float32)\n        p = probs[:, c].astype(np.float32)\n        pos = np.sum(y_true == 1)\n        neg = np.sum(y_true == 0)\n        if pos == 0 or neg == 0:\n            thresholds[c] = 0.5\n            continue\n        best_t, best_j = 0.5, -1.0\n        for t in grid:\n            yhat = (p >= t).astype(np.float32)\n            tp = np.sum((yhat == 1) & (y_true == 1))\n            fp = np.sum((yhat == 1) & (y_true == 0))\n            fn = np.sum((yhat == 0) & (y_true == 1))\n            tn = np.sum((yhat == 0) & (y_true == 0))\n            tpr = tp / (tp + fn + 1e-9)\n            fpr = fp / (fp + tn + 1e-9)\n            j = tpr - fpr\n            if j > best_j:\n                best_j = j\n                best_t = t\n        thresholds[c] = best_t\n    return thresholds\n\nif TRAINING:\n    thresholds = compute_optimal_thresholds(model, val_images, val_modalities, val_labels)\n    np.save(THRESH_FILE, thresholds)\n    print(\"Saved class-wise thresholds to:\", THRESH_FILE)\nelse:\n    thresholds = np.load(THRESH_FILE) if os.path.exists(THRESH_FILE) else np.full((len(label_columns),), 0.5, dtype=np.float32)\n\n# ============================\n# 9) 推論（シリーズ集約 + しきい値適用オプション）\n# ============================\nID_COL = 'SeriesInstanceUID'\nLABEL_COLS = list(label_columns)\n\ndef aggregate_series_probs(frame_probs, k=None):\n    frame_probs = np.asarray(frame_probs)  # (T, C)\n    if k is None or k <= 1 or k > frame_probs.shape[0]:\n        return frame_probs.max(axis=0)\n    idx = np.argsort(frame_probs, axis=0)[-k:]\n    topk = np.take_along_axis(frame_probs, idx, axis=0)\n    return topk.mean(axis=0)\n\ndef predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n    series_id = os.path.basename(series_path)\n    all_filepaths = []\n    for root, _, files in os.walk(series_path):\n        for file in files:\n            if file.endswith('.dcm'):\n                all_filepaths.append(os.path.join(root, file))\n    all_filepaths.sort()\n\n    image_list, mod_list = [], []\n    for image_path in all_filepaths:\n        dcm = pydicom.dcmread(image_path)\n        image = dcm.pixel_array\n        mod = encoder_mod.transform([[dcm.Modality]])\n        if len(image.shape) == 3:  # multiframe\n            for frame in image:\n                image_resized, _, _ = preprocess_images(frame, -1, -1, crop=False, augmentation=False)\n                image_list.append(tf.cast(image_resized, tf.float32))\n                mod_list.append(tf.cast(mod, tf.float32))\n        else:  # single frame\n            image_resized, _, _ = preprocess_images(image, -1, -1, crop=False, augmentation=False)\n            image_list.append(tf.cast(image_resized, tf.float32))\n            mod_list.append(tf.cast(mod, tf.float32))\n\n    test_images = tf.concat(image_list, axis=0)\n    test_mods   = tf.concat(mod_list,   axis=0)\n\n    lab, _ = model.predict((test_images, test_mods), verbose=0)  # (T, C)\n    prob_lab = aggregate_series_probs(lab, k=None)  # max集約（必要なら k=3 等に）\n\n    if APPLY_THRESHOLDS:\n        th = thresholds if 'thresholds' in globals() else np.full_like(prob_lab, 0.5)\n        out_vec = (prob_lab >= th).astype(float).tolist()\n    else:\n        out_vec = prob_lab.astype(float).tolist()\n\n    predictions = pl.DataFrame(\n        data=[[series_id] + out_vec],\n        schema=[ID_COL, *LABEL_COLS], orient='row'\n    )\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    # 競技が確率提出の場合は APPLY_THRESHOLDS=False を維持してください\n    return predictions.drop(ID_COL)\n\n# ============================\n# 10) 提出サーバ（SUBMISSIONING=Trueのとき）\n# ============================\nif SUBMISSIONING:\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n        inference_server.serve()\n    else:\n        inference_server.run_local_gateway()\n        try:\n            display(pl.read_parquet('/kaggle/working/submission.parquet'))\n        except Exception:\n            pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}