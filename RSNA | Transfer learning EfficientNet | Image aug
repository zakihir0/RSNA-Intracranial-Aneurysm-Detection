{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6234467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T20:29:56.805608Z",
     "iopub.status.busy": "2025-10-10T20:29:56.805090Z",
     "iopub.status.idle": "2025-10-10T21:18:01.619688Z",
     "shell.execute_reply": "2025-10-10T21:18:01.618854Z"
    },
    "papermill": {
     "duration": 2884.819899,
     "end_time": "2025-10-10T21:18:01.621012",
     "exception": false,
     "start_time": "2025-10-10T20:29:56.801113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 20:30:01.902262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760128202.102650      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760128202.153370      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1760128215.495270      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:909: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Using CPU/GPU\n",
      "REPLICAS: 1\n",
      "✅ Fold 0: Train size = 4264, Val size = 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3586/4264 [05:04<00:55, 12.31it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      " 84%|████████▍ | 3585/4264 [04:05<00:45, 14.86it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      " 84%|████████▍ | 3585/4264 [04:03<00:44, 15.22it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      " 84%|████████▍ | 3585/4264 [04:04<00:48, 14.11it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Building a fresh model.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760129668.915787      57 service.cc:148] XLA service 0x3c1394b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1760129668.916550      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1760129676.386282      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1760129732.652009      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - class_loss: 0.0161 - class_val_class_auc: 0.5849 - loss: 0.0379 - reg_loss: 2.2009 - reg_mae: 1.1882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1760129750.502654      58 assert_op.cc:38] Ignoring Assert operator RSNA_Class_1/rescaling_1/grayscale_to_rgb/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1760129750.502793      58 assert_op.cc:38] Ignoring Assert operator RSNA_Class_1/rescaling_1/grayscale_to_rgb/assert_greater_equal/Assert/Assert\n",
      "W0000 00:00:1760129755.831392      57 assert_op.cc:38] Ignoring Assert operator RSNA_Class_1/rescaling_1/grayscale_to_rgb/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1760129755.831459      57 assert_op.cc:38] Ignoring Assert operator RSNA_Class_1/rescaling_1/grayscale_to_rgb/assert_greater_equal/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 464ms/step - class_loss: 0.0161 - class_val_class_auc: 0.5854 - loss: 0.0379 - reg_loss: 2.1977 - reg_mae: 1.1872 - val_class_loss: 0.0134 - val_class_val_class_auc: 0.6384 - val_loss: 0.0190 - val_reg_loss: 0.5777 - val_reg_mae: 0.6660 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_class_auc` which is not available. Available metrics are: class_loss,class_val_class_auc,loss,reg_loss,reg_mae,val_class_loss,val_class_val_class_auc,val_loss,val_reg_loss,val_reg_mae,learning_rate\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0122 - class_val_class_auc: 0.6688 - loss: 0.0279 - reg_loss: 1.5838 - reg_mae: 0.9918 - val_class_loss: 0.0127 - val_class_val_class_auc: 0.6919 - val_loss: 0.0173 - val_reg_loss: 0.4780 - val_reg_mae: 0.5993 - learning_rate: 1.2589e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0106 - class_val_class_auc: 0.7083 - loss: 0.0248 - reg_loss: 1.4324 - reg_mae: 0.9476 - val_class_loss: 0.0111 - val_class_val_class_auc: 0.7131 - val_loss: 0.0154 - val_reg_loss: 0.4347 - val_reg_mae: 0.5523 - learning_rate: 1.5849e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0100 - class_val_class_auc: 0.7256 - loss: 0.0224 - reg_loss: 1.2548 - reg_mae: 0.8881 - val_class_loss: 0.0093 - val_class_val_class_auc: 0.7332 - val_loss: 0.0134 - val_reg_loss: 0.4233 - val_reg_mae: 0.5280 - learning_rate: 1.9953e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0089 - class_val_class_auc: 0.7547 - loss: 0.0200 - reg_loss: 1.1213 - reg_mae: 0.8437 - val_class_loss: 0.0083 - val_class_val_class_auc: 0.7476 - val_loss: 0.0128 - val_reg_loss: 0.4608 - val_reg_mae: 0.5426 - learning_rate: 2.5119e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: 0.0081 - class_val_class_auc: 0.7628 - loss: 0.0185 - reg_loss: 1.0507 - reg_mae: 0.8132 - val_class_loss: 0.0076 - val_class_val_class_auc: 0.7699 - val_loss: 0.0122 - val_reg_loss: 0.4699 - val_reg_mae: 0.5430 - learning_rate: 3.1623e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0080 - class_val_class_auc: 0.7771 - loss: 0.0174 - reg_loss: 0.9446 - reg_mae: 0.7681 - val_class_loss: 0.0073 - val_class_val_class_auc: 0.7918 - val_loss: 0.0119 - val_reg_loss: 0.4691 - val_reg_mae: 0.5385 - learning_rate: 3.9811e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0073 - class_val_class_auc: 0.7980 - loss: 0.0161 - reg_loss: 0.8871 - reg_mae: 0.7462 - val_class_loss: 0.0068 - val_class_val_class_auc: 0.8083 - val_loss: 0.0112 - val_reg_loss: 0.4471 - val_reg_mae: 0.5255 - learning_rate: 5.0119e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0066 - class_val_class_auc: 0.8219 - loss: 0.0145 - reg_loss: 0.7913 - reg_mae: 0.7019 - val_class_loss: 0.0066 - val_class_val_class_auc: 0.8221 - val_loss: 0.0108 - val_reg_loss: 0.4241 - val_reg_mae: 0.5118 - learning_rate: 6.3096e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0066 - class_val_class_auc: 0.8306 - loss: 0.0135 - reg_loss: 0.6989 - reg_mae: 0.6627 - val_class_loss: 0.0066 - val_class_val_class_auc: 0.8383 - val_loss: 0.0104 - val_reg_loss: 0.3902 - val_reg_mae: 0.4878 - learning_rate: 7.9433e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0059 - class_val_class_auc: 0.8536 - loss: 0.0121 - reg_loss: 0.6186 - reg_mae: 0.6109 - val_class_loss: 0.0063 - val_class_val_class_auc: 0.8482 - val_loss: 0.0098 - val_reg_loss: 0.3481 - val_reg_mae: 0.4586 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0060 - class_val_class_auc: 0.8580 - loss: 0.0111 - reg_loss: 0.5190 - reg_mae: 0.5558 - val_class_loss: 0.0065 - val_class_val_class_auc: 0.8526 - val_loss: 0.0094 - val_reg_loss: 0.2925 - val_reg_mae: 0.4116 - learning_rate: 1.2589e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0057 - class_val_class_auc: 0.8643 - loss: 0.0095 - reg_loss: 0.3911 - reg_mae: 0.4874 - val_class_loss: 0.0065 - val_class_val_class_auc: 0.8667 - val_loss: 0.0089 - val_reg_loss: 0.2404 - val_reg_mae: 0.3664 - learning_rate: 1.5849e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0056 - class_val_class_auc: 0.8721 - loss: 0.0089 - reg_loss: 0.3378 - reg_mae: 0.4529 - val_class_loss: 0.0067 - val_class_val_class_auc: 0.8678 - val_loss: 0.0085 - val_reg_loss: 0.1888 - val_reg_mae: 0.3168 - learning_rate: 1.9953e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0053 - class_val_class_auc: 0.8765 - loss: 0.0078 - reg_loss: 0.2527 - reg_mae: 0.3941 - val_class_loss: 0.0059 - val_class_val_class_auc: 0.8822 - val_loss: 0.0079 - val_reg_loss: 0.2105 - val_reg_mae: 0.3422 - learning_rate: 2.5119e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0054 - class_val_class_auc: 0.8854 - loss: 0.0075 - reg_loss: 0.2174 - reg_mae: 0.3582 - val_class_loss: 0.0056 - val_class_val_class_auc: 0.8899 - val_loss: 0.0072 - val_reg_loss: 0.1628 - val_reg_mae: 0.2922 - learning_rate: 3.1623e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0044 - class_val_class_auc: 0.9010 - loss: 0.0064 - reg_loss: 0.2012 - reg_mae: 0.3459 - val_class_loss: 0.0062 - val_class_val_class_auc: 0.8892 - val_loss: 0.0079 - val_reg_loss: 0.1690 - val_reg_mae: 0.2944 - learning_rate: 3.9811e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0045 - class_val_class_auc: 0.9013 - loss: 0.0063 - reg_loss: 0.1902 - reg_mae: 0.3352 - val_class_loss: 0.0052 - val_class_val_class_auc: 0.8977 - val_loss: 0.0068 - val_reg_loss: 0.1620 - val_reg_mae: 0.2926 - learning_rate: 5.0119e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0048 - class_val_class_auc: 0.8985 - loss: 0.0066 - reg_loss: 0.1803 - reg_mae: 0.3182 - val_class_loss: 0.0065 - val_class_val_class_auc: 0.8905 - val_loss: 0.0082 - val_reg_loss: 0.1725 - val_reg_mae: 0.2605 - learning_rate: 6.3096e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0054 - class_val_class_auc: 0.8979 - loss: 0.0076 - reg_loss: 0.2269 - reg_mae: 0.3556 - val_class_loss: 0.0066 - val_class_val_class_auc: 0.8967 - val_loss: 0.0089 - val_reg_loss: 0.2319 - val_reg_mae: 0.3586 - learning_rate: 7.9433e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0052 - class_val_class_auc: 0.8969 - loss: 0.0071 - reg_loss: 0.1974 - reg_mae: 0.3328 - val_class_loss: 0.0067 - val_class_val_class_auc: 0.8855 - val_loss: 0.0085 - val_reg_loss: 0.1916 - val_reg_mae: 0.2990 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0056 - class_val_class_auc: 0.8862 - loss: 0.0086 - reg_loss: 0.3066 - reg_mae: 0.3704 - val_class_loss: 0.0091 - val_class_val_class_auc: 0.8433 - val_loss: 0.0123 - val_reg_loss: 0.3280 - val_reg_mae: 0.4769 - learning_rate: 0.0013\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0072 - class_val_class_auc: 0.8655 - loss: 0.0109 - reg_loss: 0.3736 - reg_mae: 0.4552 - val_class_loss: 0.0069 - val_class_val_class_auc: 0.8588 - val_loss: 0.0087 - val_reg_loss: 0.1952 - val_reg_mae: 0.3189 - learning_rate: 0.0016\n",
      "Epoch 24/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0064 - class_val_class_auc: 0.8733 - loss: 0.0085 - reg_loss: 0.2216 - reg_mae: 0.3518 - val_class_loss: 0.0059 - val_class_val_class_auc: 0.8937 - val_loss: 0.0081 - val_reg_loss: 0.2323 - val_reg_mae: 0.3525 - learning_rate: 0.0020\n",
      "Epoch 25/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0062 - class_val_class_auc: 0.8815 - loss: 0.0080 - reg_loss: 0.1926 - reg_mae: 0.3068 - val_class_loss: 0.0132 - val_class_val_class_auc: 0.8437 - val_loss: 0.0157 - val_reg_loss: 0.2591 - val_reg_mae: 0.3663 - learning_rate: 0.0025\n",
      "Epoch 26/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0082 - class_val_class_auc: 0.8554 - loss: 0.0109 - reg_loss: 0.2841 - reg_mae: 0.3631 - val_class_loss: 0.0175 - val_class_val_class_auc: 0.7332 - val_loss: 0.0270 - val_reg_loss: 0.9646 - val_reg_mae: 0.7241 - learning_rate: 0.0032\n",
      "Epoch 27/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0102 - class_val_class_auc: 0.7974 - loss: 0.0153 - reg_loss: 0.5199 - reg_mae: 0.5310 - val_class_loss: 0.0098 - val_class_val_class_auc: 0.8619 - val_loss: 0.0128 - val_reg_loss: 0.3133 - val_reg_mae: 0.5023 - learning_rate: 0.0040\n",
      "Epoch 28/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0077 - class_val_class_auc: 0.8411 - loss: 0.0099 - reg_loss: 0.2220 - reg_mae: 0.3564 - val_class_loss: 0.0173 - val_class_val_class_auc: 0.8252 - val_loss: 0.0218 - val_reg_loss: 0.4557 - val_reg_mae: 0.5104 - learning_rate: 0.0050\n",
      "Epoch 29/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0074 - class_val_class_auc: 0.8515 - loss: 0.0093 - reg_loss: 0.1970 - reg_mae: 0.3198 - val_class_loss: 0.0117 - val_class_val_class_auc: 0.7869 - val_loss: 0.0151 - val_reg_loss: 0.3583 - val_reg_mae: 0.5284 - learning_rate: 0.0063\n",
      "Epoch 30/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0102 - class_val_class_auc: 0.8023 - loss: 0.0132 - reg_loss: 0.3148 - reg_mae: 0.4398 - val_class_loss: 0.0254 - val_class_val_class_auc: 0.6837 - val_loss: 0.0303 - val_reg_loss: 0.5216 - val_reg_mae: 0.5880 - learning_rate: 0.0079\n",
      "Epoch 31/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0089 - class_val_class_auc: 0.8249 - loss: 0.0113 - reg_loss: 0.2493 - reg_mae: 0.3790 - val_class_loss: 0.0077 - val_class_val_class_auc: 0.8651 - val_loss: 0.0098 - val_reg_loss: 0.2199 - val_reg_mae: 0.3655 - learning_rate: 0.0100\n",
      "Epoch 32/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0088 - class_val_class_auc: 0.8331 - loss: 0.0113 - reg_loss: 0.2507 - reg_mae: 0.3883 - val_class_loss: 0.0229 - val_class_val_class_auc: 0.8121 - val_loss: 0.0265 - val_reg_loss: 0.3724 - val_reg_mae: 0.4639 - learning_rate: 0.0126\n",
      "Epoch 33/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0096 - class_val_class_auc: 0.8269 - loss: 0.0120 - reg_loss: 0.2560 - reg_mae: 0.3888 - val_class_loss: nan - val_class_val_class_auc: 0.8117 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.0158\n",
      "Epoch 34/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0118 - class_val_class_auc: 0.7939 - loss: 0.0149 - reg_loss: 0.3171 - reg_mae: 0.4564 - val_class_loss: 0.0092 - val_class_val_class_auc: 0.8372 - val_loss: 0.0118 - val_reg_loss: 0.2724 - val_reg_mae: 0.4059 - learning_rate: 0.0200\n",
      "Epoch 35/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0112 - class_val_class_auc: 0.7870 - loss: 0.0150 - reg_loss: 0.3944 - reg_mae: 0.4703 - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.0251\n",
      "Epoch 36/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0159 - class_val_class_auc: 0.5409 - loss: 0.0211 - reg_loss: 0.5421 - reg_mae: 0.7295 - val_class_loss: 0.0151 - val_class_val_class_auc: 0.6421 - val_loss: 0.0203 - val_reg_loss: 0.5343 - val_reg_mae: 0.7282 - learning_rate: 0.0316\n",
      "Epoch 37/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0136 - class_val_class_auc: 0.6368 - loss: 0.0188 - reg_loss: 0.5321 - reg_mae: 0.7246 - val_class_loss: 0.0132 - val_class_val_class_auc: 0.6934 - val_loss: 0.0184 - val_reg_loss: 0.5343 - val_reg_mae: 0.7282 - learning_rate: 0.0398\n",
      "Epoch 38/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0125 - class_val_class_auc: 0.6971 - loss: 0.0178 - reg_loss: 0.5358 - reg_mae: 0.7231 - val_class_loss: 0.0134 - val_class_val_class_auc: 0.7525 - val_loss: 0.0187 - val_reg_loss: 0.5433 - val_reg_mae: 0.7266 - learning_rate: 0.0501\n",
      "Epoch 39/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0123 - class_val_class_auc: 0.6963 - loss: 0.0175 - reg_loss: 0.5295 - reg_mae: 0.7154 - val_class_loss: 0.0153 - val_class_val_class_auc: 0.7549 - val_loss: 0.0205 - val_reg_loss: 0.5366 - val_reg_mae: 0.7275 - learning_rate: 0.0631\n",
      "Epoch 40/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: 0.0123 - class_val_class_auc: 0.7162 - loss: 0.0175 - reg_loss: 0.5331 - reg_mae: 0.7240 - val_class_loss: 0.0129 - val_class_val_class_auc: 0.7401 - val_loss: 0.0181 - val_reg_loss: 0.5361 - val_reg_mae: 0.7276 - learning_rate: 0.0794\n",
      "Epoch 41/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: 0.0117 - class_val_class_auc: 0.7230 - loss: 0.0173 - reg_loss: 0.5744 - reg_mae: 0.7284 - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.1000\n",
      "Epoch 42/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: nan - class_val_class_auc: 0.4925 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.1259\n",
      "Epoch 43/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: nan - class_val_class_auc: 0.4954 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.1585\n",
      "Epoch 44/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.1995\n",
      "Epoch 45/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.2512\n",
      "Epoch 46/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.5008 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.3162\n",
      "Epoch 47/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.3981\n",
      "Epoch 48/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.5012\n",
      "Epoch 49/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.6310\n",
      "Epoch 50/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 0.7943\n",
      "Epoch 51/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1.2589\n",
      "Epoch 53/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1.5849\n",
      "Epoch 54/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1.9953\n",
      "Epoch 55/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4986 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 2.5119\n",
      "Epoch 56/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 3.1623\n",
      "Epoch 57/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 3.9811\n",
      "Epoch 58/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 5.0119\n",
      "Epoch 59/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 6.3096\n",
      "Epoch 60/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 7.9433\n",
      "Epoch 61/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 10.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 12.5893\n",
      "Epoch 63/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 15.8489\n",
      "Epoch 64/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 19.9526\n",
      "Epoch 65/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 25.1189\n",
      "Epoch 66/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 31.6228\n",
      "Epoch 67/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 39.8107\n",
      "Epoch 68/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 50.1187\n",
      "Epoch 69/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4983 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 63.0957\n",
      "Epoch 70/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 79.4328\n",
      "Epoch 71/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 100.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 125.8925\n",
      "Epoch 73/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4980 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 158.4893\n",
      "Epoch 74/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 199.5262\n",
      "Epoch 75/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4977 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 251.1886\n",
      "Epoch 76/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4986 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 316.2278\n",
      "Epoch 77/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4986 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 398.1072\n",
      "Epoch 78/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 501.1872\n",
      "Epoch 79/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 630.9573\n",
      "Epoch 80/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 794.3282\n",
      "Epoch 81/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1000.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1258.9254\n",
      "Epoch 83/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1584.8932\n",
      "Epoch 84/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 1995.2623\n",
      "Epoch 85/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 2511.8865\n",
      "Epoch 86/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 3162.2776\n",
      "Epoch 87/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 3981.0718\n",
      "Epoch 88/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 5011.8726\n",
      "Epoch 89/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 6309.5732\n",
      "Epoch 90/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4994 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 7943.2822\n",
      "Epoch 91/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4997 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 10000.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 12589.2539\n",
      "Epoch 93/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 15848.9316\n",
      "Epoch 94/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 19952.6230\n",
      "Epoch 95/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 25118.8652\n",
      "Epoch 96/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4986 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 31622.7773\n",
      "Epoch 97/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4989 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 39810.7188\n",
      "Epoch 98/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 50118.7227\n",
      "Epoch 99/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.4991 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 63095.7344\n",
      "Epoch 100/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - class_loss: nan - class_val_class_auc: 0.5000 - loss: nan - reg_loss: nan - reg_mae: nan - val_class_loss: nan - val_class_val_class_auc: 0.5000 - val_loss: nan - val_reg_loss: nan - val_reg_mae: nan - learning_rate: 79432.8203\n",
      "Model has been saved to: /kaggle/working/rsna-2xx/rsna_2_10_0_s300.keras\n"
     ]
    }
   ],
   "source": [
    "# RSNA Intracranial Aneurysm - Notebook-aligned (save & submit only customized)\n",
    "# -----------------------------------------------------------------------------\n",
    "# ◎ 変更点は「保存ファイル名」「提出設定(SUBMISSIONING)」のみ\n",
    "#    - 保存: /kaggle/working/rsna-2xx/rsna_2_10_0_s{IMAGE_SIZE}.keras へ\n",
    "#    - 読込: /kaggle/working/... -> /kaggle/input/rsna-transfer-learning-efficientnet-image-aug/rsna-2xx/... の順\n",
    "#    - SUBMISSIONING フラグで提出サーバ切替（デフォルト False）\n",
    "#\n",
    "# ◎ それ以外はノートブックの設定に合わせる\n",
    "#    - image_size=300 固定 / batch_size=64 固定\n",
    "#    - EfficientNetV2B0(weights='imagenet')\n",
    "#    - 1ch→3ch は直列化可能な Rescale レイヤ（Lambda 不使用）\n",
    "#    - 学習率スケジューラ: lr = 1e-5 * 10**(epoch/10)\n",
    "#    - StratifiedGroupKFold(10fold) 先頭fold\n",
    "#    - 集約: フレーム→シリーズは max\n",
    "#    - EMA/Top-K/しきい値最適化などは使用しない\n",
    "\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import tensorflow as tf\n",
    "import pydicom\n",
    "import kaggle_evaluation.rsna_inference_server\n",
    "\n",
    "# ============================\n",
    "# 0) 環境/パス設定（提出関連のみカスタム）\n",
    "# ============================\n",
    "SUBMISSIONING = False  # False: 学習→保存 / True: 推論サーバのみ\n",
    "\n",
    "IMAGE_SIZE = 300\n",
    "image_size = IMAGE_SIZE\n",
    "\n",
    "MODEL_DIR_WORK = \"/kaggle/working/rsna-2xx\"\n",
    "MODEL_DIR_INPUT = \"/kaggle/input/rsna-transfer-learning-efficientnet-image-aug/rsna-2xx\"\n",
    "MODEL_NAME = f\"rsna_2_10_0_s{IMAGE_SIZE}.keras\"\n",
    "MODEL_PATH_WORK = os.path.join(MODEL_DIR_WORK, MODEL_NAME)\n",
    "MODEL_PATH_INPUT = os.path.join(MODEL_DIR_INPUT, MODEL_NAME)\n",
    "os.makedirs(MODEL_DIR_WORK, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# Device / Mixed precision（ノートブック準拠）\n",
    "# ============================\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu='local')\n",
    "    print('✅ Running on TPU ', tpu.master())\n",
    "except Exception:\n",
    "    print('❌ Using CPU/GPU')\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"REPLICAS:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# ============================\n",
    "# 1) データ読み込みと分割（ノートブック準拠）\n",
    "# ============================\n",
    "path = '/kaggle/input/rsna-intracranial-aneurysm-detection/'\n",
    "trainval = pd.read_csv(os.path.join(path, \"train.csv\"))\n",
    "trainval_localizers = pd.read_csv(os.path.join(path, \"train_localizers.csv\"))\n",
    "trainval = trainval.merge(trainval_localizers, on='SeriesInstanceUID', how='outer')\n",
    "\n",
    "label_columns = trainval.columns[trainval.columns.str.contains('Artery|Tip|Other|Present', case=True)]\n",
    "label2class = {}\n",
    "trainval['class'] = 0\n",
    "for i, col in enumerate(label_columns[:]):\n",
    "    label2class[col] = i + 1\n",
    "    if i < 13:\n",
    "        trainval['class'] = trainval['class'] + trainval[col] * (i + 1)\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=33)\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    skf.split(trainval, y=trainval['class'], groups=trainval['SeriesInstanceUID'])\n",
    "):\n",
    "    train = trainval.iloc[train_idx].reset_index(drop=True)\n",
    "    val   = trainval.iloc[val_idx].reset_index(drop=True)\n",
    "    print(f\"✅ Fold {fold}: Train size = {len(train_idx)}, Val size = {len(val_idx)}\")\n",
    "    break\n",
    "\n",
    "# ============================\n",
    "# 2) 画像前処理（ノートブック準拠）\n",
    "# ============================\n",
    "def crop_image(image, x, y, tol=0.05, crop=True):\n",
    "    img = image[0, :, :, 0]\n",
    "    mask = img > tol\n",
    "    if crop and mask.sum() > 1000:\n",
    "        masked_idx = np.ix_(mask.any(1), mask.any(0))\n",
    "        image = img[masked_idx]\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], 1)\n",
    "    if crop and x >= 0 and mask.sum() > 1000:\n",
    "        coor = np.zeros((img.shape), dtype=float)\n",
    "        coor[round(y), round(x)] = 1\n",
    "        coor_masked = coor[masked_idx]\n",
    "        row, col = np.where(coor_masked == 1)\n",
    "        y, x = row[0], col[0]\n",
    "    return image, x, y\n",
    "\n",
    "def pad_and_resize(image, x, y):\n",
    "    _, h, w, _ = image.shape\n",
    "    pad_size = max(h, w)\n",
    "    image_padded = tf.image.resize_with_crop_or_pad(image, pad_size, pad_size)\n",
    "    image_resized = tf.image.resize(image_padded, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.BICUBIC)\n",
    "    if x >= 0:\n",
    "        coor = np.zeros((image.shape), dtype=float)\n",
    "        coor[:, round(y), round(x), :] = 1\n",
    "        coor_padded = tf.image.resize_with_crop_or_pad(coor, pad_size, pad_size)\n",
    "        coor_resized = tf.image.resize(coor_padded, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.AREA)\n",
    "        _, row, col, _ = np.where(coor_resized.numpy() == coor_resized.numpy().max())\n",
    "        y, x = row[0], col[0]\n",
    "    return image_resized, x, y\n",
    "\n",
    "def image_augmentation(image, x, y, augmentation=True):\n",
    "    if augmentation:\n",
    "        coor = np.zeros((image.shape), dtype=float)\n",
    "        zoom_fac = np.random.uniform(0.0, 0.0)\n",
    "        rot_fac = np.random.uniform(-0.1, 0.1)\n",
    "        trans_fac = np.random.uniform(-0.05, 0.05)\n",
    "        z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(image)\n",
    "        z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n",
    "        image = tf.keras.layers.RandomTranslation(\n",
    "            height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n",
    "            interpolation='nearest', fill_mode='constant', name='auglay3'\n",
    "        )(z)\n",
    "        if x >= 0:\n",
    "            coor[:, round(y), round(x), :] = 1\n",
    "            coor = tf.convert_to_tensor(coor)\n",
    "            z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(coor)\n",
    "            z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n",
    "            coor = tf.keras.layers.RandomTranslation(\n",
    "                height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n",
    "                interpolation='nearest', fill_mode='constant', name='auglay3'\n",
    "            )(z)\n",
    "            _, row, col, _ = np.where(coor.numpy() == coor.numpy().max())\n",
    "            y, x = row[0], col[0]\n",
    "    return image, x, y\n",
    "\n",
    "def preprocess_images(image, x, y, crop, augmentation):\n",
    "    # MinMax -> 0..1 -> 0..255 に戻して uint8（ノートブック流儀）\n",
    "    image_scaled = (MinMaxScaler().fit_transform(image.reshape(-1, 1))).reshape(1, image.shape[0], image.shape[1], 1).astype(np.float32)\n",
    "    try:\n",
    "        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=crop)\n",
    "    except Exception:\n",
    "        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=False)\n",
    "    image_aug, x_a, y_a = image_augmentation(image_c, x_c, y_c, augmentation=augmentation)\n",
    "    image_resized, x_r, y_r = pad_and_resize(image_aug, x_a, y_a)\n",
    "    image_resized = tf.cast(image_resized*255, dtype=tf.uint8)\n",
    "    if x >= 0:\n",
    "        x_rs, y_rs = x_r/IMAGE_SIZE, y_r/IMAGE_SIZE\n",
    "    else:\n",
    "        x_rs, y_rs = -1, -1\n",
    "    return image_resized, x_rs, y_rs\n",
    "\n",
    "# ============================\n",
    "# 3) データセット作成（ノートブック準拠）\n",
    "# ============================\n",
    "iteration_nr = 4\n",
    "root_path = os.path.join(path, 'series')\n",
    "encoder_mod = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit([['MR'], ['CT']])\n",
    "\n",
    "def preprocess_step(data, iter_nr):\n",
    "    image_list, modality_list, label_list, coordinates_list = [], [], [], []\n",
    "    for idx in tqdm(data.index, leave=False):\n",
    "        data_slice = data.loc[idx]\n",
    "        subfolder_path = os.path.join(root_path, data_slice['SeriesInstanceUID'])\n",
    "\n",
    "        files_in = sorted(os.listdir(subfolder_path))\n",
    "        file_name = files_in[iter_nr] if len(files_in) > iter_nr else files_in[-1]\n",
    "        if not pd.isna(data_slice.get('SOPInstanceUID')):\n",
    "            file_name = f\"{data_slice['SOPInstanceUID']}.dcm\"\n",
    "\n",
    "        dcm = pydicom.dcmread(os.path.join(subfolder_path, file_name))\n",
    "        try:\n",
    "            nr_frames = int(getattr(dcm, \"NumberOfFrames\"))\n",
    "            if data_slice['Aneurysm Present'] == 1:\n",
    "                frame_nr = int(eval(data_slice['coordinates'])['f'])\n",
    "            else:\n",
    "                frame_nr = min(iter_nr, nr_frames-1)\n",
    "        except Exception:\n",
    "            frame_nr = 0\n",
    "\n",
    "        if hasattr(pydicom, 'pixels'):\n",
    "            image = pydicom.pixels.pixel_array(dcm, index=frame_nr)\n",
    "        else:\n",
    "            arr = dcm.pixel_array\n",
    "            image = arr[frame_nr] if arr.ndim == 3 else arr\n",
    "\n",
    "        mod = encoder_mod.transform([[dcm.Modality]])\n",
    "        if pd.isna(data_slice.get('coordinates')):\n",
    "            x, y = -1, -1\n",
    "        else:\n",
    "            xy = eval(data_slice['coordinates'])\n",
    "            x, y = xy['x'], xy['y']\n",
    "\n",
    "        image_resized, x_rs, y_rs = preprocess_images(\n",
    "            image, x, y, crop=False, augmentation=(iter_nr > 0 and data_slice['Aneurysm Present'] == 1)\n",
    "        )\n",
    "        coordinates_tensor = tf.expand_dims(tf.convert_to_tensor([x_rs, y_rs], dtype=np.float32), 0)\n",
    "        image_list.append(image_resized)\n",
    "        modality_list.append(mod)\n",
    "        coordinates_list.append(coordinates_tensor)\n",
    "\n",
    "        labels = data_slice[label_columns]\n",
    "        label_tensor = tf.expand_dims(tf.convert_to_tensor(labels, dtype=np.float32), 0)\n",
    "        label_list.append(label_tensor)\n",
    "\n",
    "    images = tf.concat(image_list, axis=0)\n",
    "    modalities = tf.concat(modality_list, axis=0)\n",
    "    labels = tf.concat(label_list, axis=0)\n",
    "    coordinates = tf.concat(coordinates_list, axis=0)\n",
    "    return images, labels, coordinates, modalities\n",
    "\n",
    "def preprocess_loop(data, iteration_nr):\n",
    "    imgs, mods, labs, coors = [], [], [], []\n",
    "    for i in range(iteration_nr):\n",
    "        di, dl, dc, dm = preprocess_step(data, i)\n",
    "        imgs.append(di); mods.append(dm); labs.append(dl); coors.append(dc)\n",
    "    return tf.concat(imgs, 0), tf.concat(labs, 0), tf.concat(coors, 0), tf.concat(mods, 0)\n",
    "\n",
    "if not SUBMISSIONING:\n",
    "    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:], iteration_nr)\n",
    "    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:], iteration_nr)\n",
    "else:\n",
    "    # 提出時の軽量化（開発補助）\n",
    "    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:64], iteration_nr)\n",
    "    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:64], iteration_nr)\n",
    "\n",
    "SEED = 42\n",
    "batch_size = 64\n",
    "batch_size_val = batch_size\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_img\": train_images, \"input_mod\": train_modalities},\n",
    "     {\"class\": train_labels, \"reg\": train_coordinates})\n",
    ").shuffle(len(train_labels), seed=SEED).repeat().batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_img\": val_images, \"input_mod\": val_modalities},\n",
    "     {\"class\": val_labels, \"reg\": val_coordinates})\n",
    ").batch(batch_size_val, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ============================\n",
    "# 4) モデル定義（ノートブック準拠: Rescale + PreProcess, Lambda 不使用）\n",
    "# ============================\n",
    "label_weights = tf.constant([1,1,1,1,1,1,1,1,1,1,1,1,1,13], dtype=tf.float32)/26\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class WeightedBinaryCrossentropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"weighted_bce_loss\", reduction='sum_over_batch_size'):\n",
    "        super().__init__(name=name, reduction=reduction)\n",
    "        self.weight_positive = 1 - tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n",
    "        self.weight_negative = tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n",
    "        self.label_weights = label_weights\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        bce = -(self.weight_positive * y_true * tf.math.log(y_pred) +\n",
    "                self.weight_negative * (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        bce = bce * self.label_weights\n",
    "        return tf.reduce_mean(bce)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Rescale(tf.keras.layers.Layer):\n",
    "    \"\"\"uint8 [0,255] → float32 [0,255] にキャストし、1ch→3chへ拡張（ノートブック準拠）\"\"\"\n",
    "    def call(self, inputs):\n",
    "        x = tf.cast(inputs, tf.float32)          # [0,255] float32\n",
    "        x = tf.image.grayscale_to_rgb(x)         # (B,H,W,3)\n",
    "        return x\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PreProcess(tf.keras.layers.Layer):\n",
    "    \"\"\"EfficientNetV2 の preprocess_input を適用（入力は 0..255 float32 を想定）\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "    def call(self, inputs):\n",
    "        # Keras の EfficientNetV2 は 0..255 想定で内部スケール・正規化\n",
    "        return self.preprocess_input(inputs)\n",
    "\n",
    "def build_model():\n",
    "    base_model = tf.keras.applications.EfficientNetV2B0(\n",
    "        include_top=False,\n",
    "        input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3],\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = True\n",
    "\n",
    "    input_img = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1), name='input_img', dtype='uint8')\n",
    "    input_mod = tf.keras.Input(shape=(2,), name='input_mod')\n",
    "\n",
    "    x = Rescale(name='rescaling')(input_img)      # 1ch→3ch（Lambda 不使用）\n",
    "    x = PreProcess(name='preprocessing')(x)       # EfficientNetV2 の前処理\n",
    "    x = base_model(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='gap2d')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='gap2d_bn')(x)\n",
    "    x = tf.keras.layers.Dropout(0.1, name='gap2d_do')(x)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(name='concat_gap')([x, input_mod])\n",
    "\n",
    "    y = tf.keras.layers.Dense(512, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc1')(x)\n",
    "    y = tf.keras.layers.BatchNormalization(name='final_bn1')(y)\n",
    "    y = tf.keras.layers.Dropout(0.1, name='final_do1')(y)\n",
    "    output_lab = tf.keras.layers.Dense(len(label2class.keys()), activation=\"sigmoid\", name='class', dtype='float32')(y)\n",
    "\n",
    "    z = tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc_reg1')(x)\n",
    "    z = tf.keras.layers.Dropout(0.1, name='final_do_reg1')(z)\n",
    "    output_coord = tf.keras.layers.Dense(2, activation=\"linear\", name='reg', dtype='float32')(z)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_img, input_mod], outputs=[output_lab, output_coord], name='RSNA_Class')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    loss_class = WeightedBinaryCrossentropy()\n",
    "    loss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\n",
    "    loss_weights = {\"reg\": 0.01, \"class\": 0.99}\n",
    "    auc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='val_class_auc')\n",
    "    metrics = {\"reg\": [\"mae\"], \"class\": [auc]}\n",
    "    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n",
    "    return model\n",
    "\n",
    "# ============================\n",
    "# 5) LR スケジューラ（ノートブック準拠）\n",
    "# ============================\n",
    "def lr_schedule(epoch):\n",
    "    return 1e-5 * (10 ** (epoch / 10.0))\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=0)\n",
    "\n",
    "# ============================\n",
    "# 6) モデルのロード/ビルド（保存先だけカスタム）\n",
    "# ============================\n",
    "def load_or_build_model():\n",
    "    custom = {\n",
    "        \"WeightedBinaryCrossentropy\": WeightedBinaryCrossentropy,\n",
    "        \"Rescale\": Rescale,\n",
    "        \"PreProcess\": PreProcess,\n",
    "    }\n",
    "    if os.path.exists(MODEL_PATH_WORK):\n",
    "        try:\n",
    "            m = tf.keras.models.load_model(MODEL_PATH_WORK, custom_objects=custom, compile=False)\n",
    "            print(f\"Loaded model from WORKING: {MODEL_PATH_WORK}\")\n",
    "            return m\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load WORKING model: {e}\")\n",
    "    if os.path.exists(MODEL_PATH_INPUT):\n",
    "        try:\n",
    "            m = tf.keras.models.load_model(MODEL_PATH_INPUT, custom_objects=custom, compile=False)\n",
    "            print(f\"Loaded model from INPUT: {MODEL_PATH_INPUT}\")\n",
    "            return m\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load INPUT model: {e}\")\n",
    "    print(\"No saved model found. Building a fresh model.\")\n",
    "    with strategy.scope():\n",
    "        return build_model()\n",
    "\n",
    "model = load_or_build_model()\n",
    "\n",
    "# 再コンパイル（load_model 時 compile=False）\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "loss_class = WeightedBinaryCrossentropy()\n",
    "loss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\n",
    "loss_weights = {\"reg\": 0.01, \"class\": 0.99}\n",
    "auc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='val_class_auc')\n",
    "metrics = {\"reg\": [\"mae\"], \"class\": [auc]}\n",
    "model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n",
    "\n",
    "# ============================\n",
    "# 7) 学習（ノートブック準拠）\n",
    "# ============================\n",
    "epochs = 100\n",
    "steps_per_epoch = max(1, len(train)//batch_size)\n",
    "TRAINING = (not SUBMISSIONING)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, monitor='val_class_auc', mode='max', restore_best_weights=True\n",
    ")\n",
    "\n",
    "if TRAINING:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[lr_cb, early_stopping_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(MODEL_PATH_WORK, include_optimizer=False)\n",
    "    print(f\"Model has been saved to: {MODEL_PATH_WORK}\")\n",
    "\n",
    "# ============================\n",
    "# 8) 推論（シリーズ集約：max のみ）\n",
    "# ============================\n",
    "ID_COL = 'SeriesInstanceUID'\n",
    "LABEL_COLS = list(label_columns)\n",
    "\n",
    "def aggregate_series_probs_max(frame_probs):\n",
    "    frame_probs = np.asarray(frame_probs)  # (T, C)\n",
    "    return frame_probs.max(axis=0)\n",
    "\n",
    "def predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n",
    "    series_id = os.path.basename(series_path)\n",
    "    all_filepaths = []\n",
    "    for root, _, files in os.walk(series_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                all_filepaths.append(os.path.join(root, file))\n",
    "    all_filepaths.sort()\n",
    "\n",
    "    image_list, mod_list = [], []\n",
    "    for image_path in all_filepaths:\n",
    "        dcm = pydicom.dcmread(image_path)\n",
    "        image = dcm.pixel_array\n",
    "        mod = encoder_mod.transform([[dcm.Modality]])\n",
    "        if len(image.shape) == 3:  # multiframe\n",
    "            for frame in image:\n",
    "                image_resized, _, _ = preprocess_images(frame, -1, -1, crop=False, augmentation=False)\n",
    "                image_list.append(tf.cast(image_resized, tf.float32))\n",
    "                mod_list.append(tf.cast(mod, tf.float32))\n",
    "        else:\n",
    "            image_resized, _, _ = preprocess_images(image, -1, -1, crop=False, augmentation=False)\n",
    "            image_list.append(tf.cast(image_resized, tf.float32))\n",
    "            mod_list.append(tf.cast(mod, tf.float32))\n",
    "\n",
    "    test_images = tf.concat(image_list, axis=0)\n",
    "    test_mods   = tf.concat(mod_list,   axis=0)\n",
    "\n",
    "    lab, _ = model.predict((test_images, test_mods), verbose=0)  # (T, C)\n",
    "    prob_lab = aggregate_series_probs_max(lab)\n",
    "\n",
    "    out_vec = prob_lab.astype(float).tolist()\n",
    "    predictions = pl.DataFrame(\n",
    "        data=[[series_id] + out_vec],\n",
    "        schema=[ID_COL, *LABEL_COLS], orient='row'\n",
    "    )\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    return predictions.drop(ID_COL)\n",
    "\n",
    "# ============================\n",
    "# 9) 提出サーバ（提出設定のみカスタム）\n",
    "# ============================\n",
    "if SUBMISSIONING:\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway()\n",
    "        try:\n",
    "            display(pl.read_parquet('/kaggle/working/submission.parquet'))\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ce57a",
   "metadata": {
    "papermill": {
     "duration": 0.645403,
     "end_time": "2025-10-10T21:18:03.019602",
     "exception": false,
     "start_time": "2025-10-10T21:18:02.374199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "sourceId": 99552,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2893.844702,
   "end_time": "2025-10-10T21:18:06.868308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-10T20:29:53.023606",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
