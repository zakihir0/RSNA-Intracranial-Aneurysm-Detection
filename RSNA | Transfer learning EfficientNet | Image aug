{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b9bfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T07:25:52.809959Z",
     "iopub.status.busy": "2025-10-10T07:25:52.809711Z",
     "iopub.status.idle": "2025-10-10T08:38:19.589884Z",
     "shell.execute_reply": "2025-10-10T08:38:19.589038Z"
    },
    "papermill": {
     "duration": 4346.785897,
     "end_time": "2025-10-10T08:38:19.591378",
     "exception": false,
     "start_time": "2025-10-10T07:25:52.805481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 07:25:57.449159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760081157.629299      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760081157.685837      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1760081170.391517      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:909: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Using CPU/GPU\n",
      "REPLICAS:  1\n",
      "✅ Fold 0: Train size = 4264, Val size = 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3586/4264 [04:39<00:50, 13.52it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      "100%|██████████| 4264/4264 [05:30<00:00, 12.91it/s]\n",
      " 84%|████████▍ | 3585/4264 [03:54<00:42, 15.87it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      "100%|██████████| 4264/4264 [04:39<00:00, 15.24it/s]\n",
      " 84%|████████▍ | 3585/4264 [03:54<00:44, 15.10it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      "100%|██████████| 4264/4264 [04:38<00:00, 15.29it/s]\n",
      " 84%|████████▍ | 3585/4264 [03:54<00:42, 15.89it/s]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n",
      "  warn_and_log(\n",
      "100%|██████████| 4264/4264 [04:39<00:00, 15.24it/s]\n",
      "100%|██████████| 475/475 [00:34<00:00, 13.64it/s]\n",
      "100%|██████████| 475/475 [00:31<00:00, 15.02it/s]\n",
      "100%|██████████| 475/475 [00:31<00:00, 15.06it/s]\n",
      "100%|██████████| 475/475 [00:31<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Building a fresh model.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760082545.560836      57 service.cc:148] XLA service 0x31b948b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1760082545.561642      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1760082552.766421      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1760082605.864494      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 417ms/step - class_auc: 0.5588 - class_loss: 0.0170 - loss: 0.0316 - reg_loss: 1.4754 - reg_mae: 0.9049 - val_class_auc: 0.6692 - val_class_loss: 0.0134 - val_loss: 0.0184 - val_reg_loss: 0.5091 - val_reg_mae: 0.6739 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.6281 - class_loss: 0.0142 - loss: 0.0235 - reg_loss: 0.9404 - reg_mae: 0.7553 - val_class_auc: 0.7266 - val_class_loss: 0.0125 - val_loss: 0.0184 - val_reg_loss: 0.6102 - val_reg_mae: 0.6551 - learning_rate: 4.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - class_auc: 0.6791 - class_loss: 0.0133 - loss: 0.0208 - reg_loss: 0.7665 - reg_mae: 0.6965 - val_class_auc: 0.7610 - val_class_loss: 0.0110 - val_loss: 0.0145 - val_reg_loss: 0.3574 - val_reg_mae: 0.5208 - learning_rate: 6.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.7159 - class_loss: 0.0120 - loss: 0.0173 - reg_loss: 0.5443 - reg_mae: 0.6043 - val_class_auc: 0.7906 - val_class_loss: 0.0115 - val_loss: 0.0157 - val_reg_loss: 0.4189 - val_reg_mae: 0.4841 - learning_rate: 8.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.7491 - class_loss: 0.0112 - loss: 0.0158 - reg_loss: 0.4786 - reg_mae: 0.5570 - val_class_auc: 0.8001 - val_class_loss: 0.0099 - val_loss: 0.0137 - val_reg_loss: 0.3889 - val_reg_mae: 0.5062 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 308ms/step - class_auc: 0.7706 - class_loss: 0.0104 - loss: 0.0143 - reg_loss: 0.3950 - reg_mae: 0.5027 - val_class_auc: 0.8003 - val_class_loss: 0.0094 - val_loss: 0.0123 - val_reg_loss: 0.2948 - val_reg_mae: 0.4284 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.7817 - class_loss: 0.0102 - loss: 0.0136 - reg_loss: 0.3500 - reg_mae: 0.4673 - val_class_auc: 0.8061 - val_class_loss: 0.0096 - val_loss: 0.0126 - val_reg_loss: 0.3302 - val_reg_mae: 0.4230 - learning_rate: 9.9973e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8106 - class_loss: 0.0088 - loss: 0.0116 - reg_loss: 0.2912 - reg_mae: 0.4173 - val_class_auc: 0.8017 - val_class_loss: 0.0117 - val_loss: 0.0144 - val_reg_loss: 0.2869 - val_reg_mae: 0.4138 - learning_rate: 9.9892e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.8224 - class_loss: 0.0084 - loss: 0.0110 - reg_loss: 0.2715 - reg_mae: 0.3968 - val_class_auc: 0.8349 - val_class_loss: 0.0082 - val_loss: 0.0105 - val_reg_loss: 0.2403 - val_reg_mae: 0.3446 - learning_rate: 9.9757e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - class_auc: 0.8221 - class_loss: 0.0085 - loss: 0.0111 - reg_loss: 0.2672 - reg_mae: 0.3876 - val_class_auc: 0.8197 - val_class_loss: 0.0123 - val_loss: 0.0172 - val_reg_loss: 0.5424 - val_reg_mae: 0.5100 - learning_rate: 9.9568e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.8161 - class_loss: 0.0086 - loss: 0.0114 - reg_loss: 0.2856 - reg_mae: 0.4074 - val_class_auc: 0.8214 - val_class_loss: 0.0113 - val_loss: 0.0146 - val_reg_loss: 0.3643 - val_reg_mae: 0.4187 - learning_rate: 9.9325e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - class_auc: 0.8364 - class_loss: 0.0077 - loss: 0.0100 - reg_loss: 0.2358 - reg_mae: 0.3574 - val_class_auc: 0.8324 - val_class_loss: 0.0106 - val_loss: 0.0141 - val_reg_loss: 0.3795 - val_reg_mae: 0.4532 - learning_rate: 9.9029e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - class_auc: 0.8413 - class_loss: 0.0073 - loss: 0.0095 - reg_loss: 0.2210 - reg_mae: 0.3455 - val_class_auc: 0.8530 - val_class_loss: 0.0093 - val_loss: 0.0121 - val_reg_loss: 0.2779 - val_reg_mae: 0.3403 - learning_rate: 9.8680e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8486 - class_loss: 0.0073 - loss: 0.0094 - reg_loss: 0.2161 - reg_mae: 0.3320 - val_class_auc: 0.8538 - val_class_loss: 0.0076 - val_loss: 0.0096 - val_reg_loss: 0.2117 - val_reg_mae: 0.2787 - learning_rate: 9.8278e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8323 - class_loss: 0.0077 - loss: 0.0099 - reg_loss: 0.2280 - reg_mae: 0.3438 - val_class_auc: 0.8504 - val_class_loss: 0.0090 - val_loss: 0.0116 - val_reg_loss: 0.2643 - val_reg_mae: 0.3477 - learning_rate: 9.7824e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8588 - class_loss: 0.0068 - loss: 0.0087 - reg_loss: 0.1975 - reg_mae: 0.3118 - val_class_auc: 0.8634 - val_class_loss: 0.0070 - val_loss: 0.0089 - val_reg_loss: 0.1903 - val_reg_mae: 0.2905 - learning_rate: 9.7318e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8592 - class_loss: 0.0068 - loss: 0.0087 - reg_loss: 0.1931 - reg_mae: 0.3053 - val_class_auc: 0.8388 - val_class_loss: 0.0125 - val_loss: 0.0169 - val_reg_loss: 0.4415 - val_reg_mae: 0.4331 - learning_rate: 9.6761e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8251 - class_loss: 0.0082 - loss: 0.0106 - reg_loss: 0.2487 - reg_mae: 0.3618 - val_class_auc: 0.8516 - val_class_loss: 0.0073 - val_loss: 0.0094 - val_reg_loss: 0.2179 - val_reg_mae: 0.3117 - learning_rate: 9.6153e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8378 - class_loss: 0.0078 - loss: 0.0099 - reg_loss: 0.2261 - reg_mae: 0.3383 - val_class_auc: 0.8437 - val_class_loss: 0.0074 - val_loss: 0.0093 - val_reg_loss: 0.2004 - val_reg_mae: 0.3213 - learning_rate: 9.5496e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8430 - class_loss: 0.0073 - loss: 0.0093 - reg_loss: 0.2108 - reg_mae: 0.3288 - val_class_auc: 0.8643 - val_class_loss: 0.0076 - val_loss: 0.0098 - val_reg_loss: 0.2141 - val_reg_mae: 0.2911 - learning_rate: 9.4789e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 307ms/step - class_auc: 0.8577 - class_loss: 0.0068 - loss: 0.0086 - reg_loss: 0.1892 - reg_mae: 0.2950 - val_class_auc: 0.8735 - val_class_loss: 0.0064 - val_loss: 0.0082 - val_reg_loss: 0.1912 - val_reg_mae: 0.2796 - learning_rate: 9.4034e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8561 - class_loss: 0.0064 - loss: 0.0081 - reg_loss: 0.1747 - reg_mae: 0.2828 - val_class_auc: 0.8664 - val_class_loss: 0.0071 - val_loss: 0.0090 - val_reg_loss: 0.2025 - val_reg_mae: 0.3014 - learning_rate: 9.3231e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8643 - class_loss: 0.0065 - loss: 0.0083 - reg_loss: 0.1841 - reg_mae: 0.2889 - val_class_auc: 0.8706 - val_class_loss: 0.0073 - val_loss: 0.0094 - val_reg_loss: 0.2132 - val_reg_mae: 0.3024 - learning_rate: 9.2382e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8716 - class_loss: 0.0058 - loss: 0.0074 - reg_loss: 0.1620 - reg_mae: 0.2707 - val_class_auc: 0.8699 - val_class_loss: 0.0117 - val_loss: 0.0153 - val_reg_loss: 0.3607 - val_reg_mae: 0.4127 - learning_rate: 9.1486e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8708 - class_loss: 0.0060 - loss: 0.0076 - reg_loss: 0.1665 - reg_mae: 0.2709 - val_class_auc: 0.6642 - val_class_loss: 0.0277 - val_loss: 0.0337 - val_reg_loss: 0.6962 - val_reg_mae: 0.6313 - learning_rate: 9.0546e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8460 - class_loss: 0.0078 - loss: 0.0100 - reg_loss: 0.2282 - reg_mae: 0.3371 - val_class_auc: 0.8546 - val_class_loss: 0.0079 - val_loss: 0.0101 - val_reg_loss: 0.2249 - val_reg_mae: 0.3310 - learning_rate: 8.9562e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8223 - class_loss: 0.0091 - loss: 0.0124 - reg_loss: 0.3409 - reg_mae: 0.4192 - val_class_auc: 0.8442 - val_class_loss: 0.0078 - val_loss: 0.0100 - val_reg_loss: 0.2307 - val_reg_mae: 0.3320 - learning_rate: 8.8536e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8285 - class_loss: 0.0083 - loss: 0.0108 - reg_loss: 0.2492 - reg_mae: 0.3651 - val_class_auc: 0.8693 - val_class_loss: 0.0070 - val_loss: 0.0089 - val_reg_loss: 0.1956 - val_reg_mae: 0.2739 - learning_rate: 8.7468e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 305ms/step - class_auc: 0.8410 - class_loss: 0.0077 - loss: 0.0097 - reg_loss: 0.2137 - reg_mae: 0.3250 - val_class_auc: 0.8597 - val_class_loss: 0.0086 - val_loss: 0.0115 - val_reg_loss: 0.3015 - val_reg_mae: 0.3525 - learning_rate: 8.6359e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8383 - class_loss: 0.0080 - loss: 0.0101 - reg_loss: 0.2205 - reg_mae: 0.3260 - val_class_auc: 0.8745 - val_class_loss: 0.0064 - val_loss: 0.0080 - val_reg_loss: 0.1692 - val_reg_mae: 0.2420 - learning_rate: 8.5211e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8511 - class_loss: 0.0073 - loss: 0.0092 - reg_loss: 0.2057 - reg_mae: 0.3143 - val_class_auc: 0.8732 - val_class_loss: 0.0063 - val_loss: 0.0080 - val_reg_loss: 0.1765 - val_reg_mae: 0.2448 - learning_rate: 8.4025e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8684 - class_loss: 0.0065 - loss: 0.0082 - reg_loss: 0.1749 - reg_mae: 0.2782 - val_class_auc: 0.8856 - val_class_loss: 0.0061 - val_loss: 0.0077 - val_reg_loss: 0.1629 - val_reg_mae: 0.2393 - learning_rate: 8.2803e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8764 - class_loss: 0.0059 - loss: 0.0075 - reg_loss: 0.1595 - reg_mae: 0.2601 - val_class_auc: 0.8702 - val_class_loss: 0.0069 - val_loss: 0.0086 - val_reg_loss: 0.1758 - val_reg_mae: 0.2673 - learning_rate: 8.1545e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8664 - class_loss: 0.0063 - loss: 0.0079 - reg_loss: 0.1707 - reg_mae: 0.2698 - val_class_auc: 0.8778 - val_class_loss: 0.0065 - val_loss: 0.0083 - val_reg_loss: 0.1900 - val_reg_mae: 0.2674 - learning_rate: 8.0254e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8684 - class_loss: 0.0062 - loss: 0.0079 - reg_loss: 0.1704 - reg_mae: 0.2657 - val_class_auc: 0.8832 - val_class_loss: 0.0064 - val_loss: 0.0083 - val_reg_loss: 0.1878 - val_reg_mae: 0.2435 - learning_rate: 7.8929e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8678 - class_loss: 0.0062 - loss: 0.0078 - reg_loss: 0.1631 - reg_mae: 0.2636 - val_class_auc: 0.8655 - val_class_loss: 0.0074 - val_loss: 0.0094 - val_reg_loss: 0.2020 - val_reg_mae: 0.2925 - learning_rate: 7.7574e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8717 - class_loss: 0.0062 - loss: 0.0079 - reg_loss: 0.1720 - reg_mae: 0.2806 - val_class_auc: 0.8741 - val_class_loss: 0.0060 - val_loss: 0.0074 - val_reg_loss: 0.1482 - val_reg_mae: 0.2170 - learning_rate: 7.6189e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8756 - class_loss: 0.0056 - loss: 0.0069 - reg_loss: 0.1412 - reg_mae: 0.2391 - val_class_auc: 0.8708 - val_class_loss: 0.0097 - val_loss: 0.0119 - val_reg_loss: 0.2264 - val_reg_mae: 0.2691 - learning_rate: 7.4776e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8863 - class_loss: 0.0056 - loss: 0.0070 - reg_loss: 0.1488 - reg_mae: 0.2440 - val_class_auc: 0.8860 - val_class_loss: 0.0057 - val_loss: 0.0072 - val_reg_loss: 0.1508 - val_reg_mae: 0.2402 - learning_rate: 7.3336e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8747 - class_loss: 0.0062 - loss: 0.0078 - reg_loss: 0.1723 - reg_mae: 0.2775 - val_class_auc: 0.8826 - val_class_loss: 0.0079 - val_loss: 0.0099 - val_reg_loss: 0.2015 - val_reg_mae: 0.2415 - learning_rate: 7.1872e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8784 - class_loss: 0.0057 - loss: 0.0071 - reg_loss: 0.1488 - reg_mae: 0.2448 - val_class_auc: 0.8553 - val_class_loss: 0.0106 - val_loss: 0.0135 - val_reg_loss: 0.2947 - val_reg_mae: 0.3414 - learning_rate: 7.0384e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8642 - class_loss: 0.0070 - loss: 0.0089 - reg_loss: 0.1991 - reg_mae: 0.3071 - val_class_auc: 0.8791 - val_class_loss: 0.0060 - val_loss: 0.0076 - val_reg_loss: 0.1631 - val_reg_mae: 0.2494 - learning_rate: 6.8874e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8605 - class_loss: 0.0071 - loss: 0.0090 - reg_loss: 0.1973 - reg_mae: 0.2998 - val_class_auc: 0.8840 - val_class_loss: 0.0058 - val_loss: 0.0073 - val_reg_loss: 0.1555 - val_reg_mae: 0.2466 - learning_rate: 6.7345e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8816 - class_loss: 0.0056 - loss: 0.0071 - reg_loss: 0.1552 - reg_mae: 0.2582 - val_class_auc: 0.8784 - val_class_loss: 0.0060 - val_loss: 0.0076 - val_reg_loss: 0.1637 - val_reg_mae: 0.2300 - learning_rate: 6.5796e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 304ms/step - class_auc: 0.8794 - class_loss: 0.0059 - loss: 0.0074 - reg_loss: 0.1523 - reg_mae: 0.2430 - val_class_auc: 0.8839 - val_class_loss: 0.0061 - val_loss: 0.0076 - val_reg_loss: 0.1555 - val_reg_mae: 0.2162 - learning_rate: 6.4231e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8803 - class_loss: 0.0056 - loss: 0.0071 - reg_loss: 0.1518 - reg_mae: 0.2429 - val_class_auc: 0.8613 - val_class_loss: 0.0081 - val_loss: 0.0098 - val_reg_loss: 0.1755 - val_reg_mae: 0.2452 - learning_rate: 6.2652e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8850 - class_loss: 0.0054 - loss: 0.0068 - reg_loss: 0.1391 - reg_mae: 0.2344 - val_class_auc: 0.8829 - val_class_loss: 0.0065 - val_loss: 0.0082 - val_reg_loss: 0.1751 - val_reg_mae: 0.2650 - learning_rate: 6.1058e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8923 - class_loss: 0.0051 - loss: 0.0064 - reg_loss: 0.1360 - reg_mae: 0.2295 - val_class_auc: 0.8874 - val_class_loss: 0.0056 - val_loss: 0.0069 - val_reg_loss: 0.1389 - val_reg_mae: 0.1980 - learning_rate: 5.9454e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8976 - class_loss: 0.0046 - loss: 0.0058 - reg_loss: 0.1183 - reg_mae: 0.2081 - val_class_auc: 0.8727 - val_class_loss: 0.0083 - val_loss: 0.0103 - val_reg_loss: 0.2086 - val_reg_mae: 0.3004 - learning_rate: 5.7839e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.8948 - class_loss: 0.0048 - loss: 0.0060 - reg_loss: 0.1210 - reg_mae: 0.2128 - val_class_auc: 0.8796 - val_class_loss: 0.0091 - val_loss: 0.0104 - val_reg_loss: 0.1437 - val_reg_mae: 0.1936 - learning_rate: 5.6216e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8979 - class_loss: 0.0048 - loss: 0.0060 - reg_loss: 0.1234 - reg_mae: 0.2093 - val_class_auc: 0.8802 - val_class_loss: 0.0062 - val_loss: 0.0078 - val_reg_loss: 0.1603 - val_reg_mae: 0.2293 - learning_rate: 5.4588e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 303ms/step - class_auc: 0.8814 - class_loss: 0.0054 - loss: 0.0067 - reg_loss: 0.1368 - reg_mae: 0.2313 - val_class_auc: 0.8890 - val_class_loss: 0.0061 - val_loss: 0.0077 - val_reg_loss: 0.1684 - val_reg_mae: 0.2246 - learning_rate: 5.2954e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8918 - class_loss: 0.0051 - loss: 0.0063 - reg_loss: 0.1246 - reg_mae: 0.2182 - val_class_auc: 0.8816 - val_class_loss: 0.0092 - val_loss: 0.0115 - val_reg_loss: 0.2377 - val_reg_mae: 0.2772 - learning_rate: 5.1318e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8977 - class_loss: 0.0047 - loss: 0.0059 - reg_loss: 0.1163 - reg_mae: 0.2046 - val_class_auc: 0.8893 - val_class_loss: 0.0060 - val_loss: 0.0075 - val_reg_loss: 0.1583 - val_reg_mae: 0.2206 - learning_rate: 4.9682e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8960 - class_loss: 0.0048 - loss: 0.0060 - reg_loss: 0.1199 - reg_mae: 0.2121 - val_class_auc: 0.8832 - val_class_loss: 0.0060 - val_loss: 0.0075 - val_reg_loss: 0.1544 - val_reg_mae: 0.2129 - learning_rate: 4.8046e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.8993 - class_loss: 0.0046 - loss: 0.0057 - reg_loss: 0.1130 - reg_mae: 0.2037 - val_class_auc: 0.8911 - val_class_loss: 0.0057 - val_loss: 0.0072 - val_reg_loss: 0.1477 - val_reg_mae: 0.2215 - learning_rate: 4.6412e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9005 - class_loss: 0.0043 - loss: 0.0053 - reg_loss: 0.1058 - reg_mae: 0.1951 - val_class_auc: 0.8873 - val_class_loss: 0.0063 - val_loss: 0.0079 - val_reg_loss: 0.1683 - val_reg_mae: 0.2266 - learning_rate: 4.4784e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.8986 - class_loss: 0.0042 - loss: 0.0052 - reg_loss: 0.1025 - reg_mae: 0.1882 - val_class_auc: 0.8756 - val_class_loss: 0.0069 - val_loss: 0.0087 - val_reg_loss: 0.1830 - val_reg_mae: 0.2521 - learning_rate: 4.3161e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9026 - class_loss: 0.0041 - loss: 0.0051 - reg_loss: 0.0990 - reg_mae: 0.1926 - val_class_auc: 0.8877 - val_class_loss: 0.0068 - val_loss: 0.0085 - val_reg_loss: 0.1686 - val_reg_mae: 0.2122 - learning_rate: 4.1546e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.9041 - class_loss: 0.0042 - loss: 0.0053 - reg_loss: 0.1060 - reg_mae: 0.1929 - val_class_auc: 0.8909 - val_class_loss: 0.0060 - val_loss: 0.0075 - val_reg_loss: 0.1535 - val_reg_mae: 0.2198 - learning_rate: 3.9942e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9078 - class_loss: 0.0037 - loss: 0.0045 - reg_loss: 0.0796 - reg_mae: 0.1599 - val_class_auc: 0.8896 - val_class_loss: 0.0070 - val_loss: 0.0086 - val_reg_loss: 0.1709 - val_reg_mae: 0.2034 - learning_rate: 3.8348e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9061 - class_loss: 0.0037 - loss: 0.0044 - reg_loss: 0.0785 - reg_mae: 0.1573 - val_class_auc: 0.8861 - val_class_loss: 0.0068 - val_loss: 0.0084 - val_reg_loss: 0.1614 - val_reg_mae: 0.2057 - learning_rate: 3.6769e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 302ms/step - class_auc: 0.9137 - class_loss: 0.0033 - loss: 0.0040 - reg_loss: 0.0715 - reg_mae: 0.1517 - val_class_auc: 0.8733 - val_class_loss: 0.0094 - val_loss: 0.0117 - val_reg_loss: 0.2491 - val_reg_mae: 0.2841 - learning_rate: 3.5204e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9065 - class_loss: 0.0037 - loss: 0.0045 - reg_loss: 0.0806 - reg_mae: 0.1648 - val_class_auc: 0.8889 - val_class_loss: 0.0064 - val_loss: 0.0079 - val_reg_loss: 0.1497 - val_reg_mae: 0.1904 - learning_rate: 3.3655e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.9162 - class_loss: 0.0029 - loss: 0.0034 - reg_loss: 0.0569 - reg_mae: 0.1367 - val_class_auc: 0.8893 - val_class_loss: 0.0070 - val_loss: 0.0085 - val_reg_loss: 0.1540 - val_reg_mae: 0.1923 - learning_rate: 3.2126e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 299ms/step - class_auc: 0.9194 - class_loss: 0.0030 - loss: 0.0035 - reg_loss: 0.0601 - reg_mae: 0.1367 - val_class_auc: 0.8810 - val_class_loss: 0.0078 - val_loss: 0.0095 - val_reg_loss: 0.1787 - val_reg_mae: 0.2138 - learning_rate: 3.0616e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.9157 - class_loss: 0.0030 - loss: 0.0035 - reg_loss: 0.0582 - reg_mae: 0.1368 - val_class_auc: 0.8813 - val_class_loss: 0.0069 - val_loss: 0.0085 - val_reg_loss: 0.1672 - val_reg_mae: 0.2327 - learning_rate: 2.9128e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9150 - class_loss: 0.0032 - loss: 0.0039 - reg_loss: 0.0684 - reg_mae: 0.1518 - val_class_auc: 0.8900 - val_class_loss: 0.0067 - val_loss: 0.0082 - val_reg_loss: 0.1556 - val_reg_mae: 0.1836 - learning_rate: 2.7664e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.9160 - class_loss: 0.0027 - loss: 0.0032 - reg_loss: 0.0507 - reg_mae: 0.1243 - val_class_auc: 0.8778 - val_class_loss: 0.0092 - val_loss: 0.0108 - val_reg_loss: 0.1694 - val_reg_mae: 0.1875 - learning_rate: 2.6224e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 300ms/step - class_auc: 0.9157 - class_loss: 0.0023 - loss: 0.0027 - reg_loss: 0.0373 - reg_mae: 0.1141 - val_class_auc: 0.8783 - val_class_loss: 0.0089 - val_loss: 0.0108 - val_reg_loss: 0.1893 - val_reg_mae: 0.2049 - learning_rate: 2.4811e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 301ms/step - class_auc: 0.9216 - class_loss: 0.0023 - loss: 0.0026 - reg_loss: 0.0386 - reg_mae: 0.1129 - val_class_auc: 0.8763 - val_class_loss: 0.0084 - val_loss: 0.0101 - val_reg_loss: 0.1823 - val_reg_mae: 0.2082 - learning_rate: 2.3426e-04\n",
      "Model weights have been saved to: /kaggle/working/rsna-2xx/rsna_2_10_0.keras\n",
      "Saved class-wise thresholds to: /kaggle/working/rsna-2xx/class_thresholds.npy\n"
     ]
    }
   ],
   "source": [
    "# RSNA Intracranial Aneurysm - Single-Page Script (Complete)\n",
    "# ---------------------------------------------------------------\n",
    "# 改善点:\n",
    "# 1) Cosine+Warmup LR (+EMA)\n",
    "# 2) 入力解像度384 + Mixed Precision (AMP) + LearnableRGB(Conv1x1)\n",
    "# 3) クラス別しきい値最適化（Youden J; 提出時は通常OFF）\n",
    "#\n",
    "# 保存/読込:\n",
    "# - 学習時(SUBMISSIONING=False)は /kaggle/working/rsna-2xx/rsna_2_10_0.h5 に保存\n",
    "# - 読込は /kaggle/working → /kaggle/input の順で探索\n",
    "#\n",
    "# 依存:\n",
    "# - Kaggle 環境を想定（RSNAコンペ入出力構成）\n",
    "# - 外部DLが困難な環境に備え、EfficientNetV2のweightsは既定でNone（=DLしない）\n",
    "\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pydicom\n",
    "import kaggle_evaluation.rsna_inference_server\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 0) 環境/パス設定\n",
    "# ============================\n",
    "# ここを False にすると学習→ /kaggle/working に保存します\n",
    "SUBMISSIONING = False\n",
    "\n",
    "# モデル保存/読込パス\n",
    "MODEL_DIR_WORK = \"/kaggle/working/rsna-2xx\"\n",
    "MODEL_DIR_INPUT = \"/kaggle/input/rsna-transfer-learning-efficientnet-image-aug/rsna-2xx\"\n",
    "MODEL_NAME = \"rsna_2_10_0.keras\"\n",
    "MODEL_PATH_WORK = os.path.join(MODEL_DIR_WORK, MODEL_NAME)\n",
    "MODEL_PATH_INPUT = os.path.join(MODEL_DIR_INPUT, MODEL_NAME)\n",
    "os.makedirs(MODEL_DIR_WORK, exist_ok=True)\n",
    "\n",
    "# オフライン安全: ImageNet重みDLを避ける（必要なら環境変数で上書き）\n",
    "USE_IMAGENET = os.getenv(\"USE_IMAGENET\", \"0\") in (\"1\", \"true\", \"True\")\n",
    "LOCAL_WEIGHTS = os.getenv(\"LOCAL_WEIGHTS\", \"\")  # ベースCNNのローカル重みがある場合\n",
    "\n",
    "# Mixed Precision\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu='local')\n",
    "    print('✅ Running on TPU ', tpu.master())\n",
    "except Exception:\n",
    "    print('❌ Using CPU/GPU')\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "# ============================\n",
    "# 1) データ読み込みと分割\n",
    "# ============================\n",
    "path = '/kaggle/input/rsna-intracranial-aneurysm-detection/'\n",
    "trainval = pd.read_csv(os.path.join(path, \"train.csv\"))\n",
    "trainval_localizers = pd.read_csv(os.path.join(path, \"train_localizers.csv\"))\n",
    "trainval = trainval.merge(trainval_localizers, on='SeriesInstanceUID', how='outer')\n",
    "\n",
    "# StratifiedGroupKFold 用クラス作成（多ラベル→多クラス）\n",
    "label_columns = trainval.columns[trainval.columns.str.contains('Artery|Tip|Other|Present', case=True)]\n",
    "label2class = {}\n",
    "trainval['class'] = 0\n",
    "for i, col in enumerate(label_columns[:]):\n",
    "    label2class[col] = i + 1\n",
    "    if i < 13:\n",
    "        trainval['class'] = trainval['class'] + trainval[col] * (i + 1)\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=33)\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    skf.split(trainval, y=trainval['class'], groups=trainval['SeriesInstanceUID'])\n",
    "):\n",
    "    train = trainval.iloc[train_idx].reset_index(drop=True)\n",
    "    val   = trainval.iloc[val_idx].reset_index(drop=True)\n",
    "    print(f\"✅ Fold {fold}: Train size = {len(train_idx)}, Val size = {len(val_idx)}\")\n",
    "    break\n",
    "\n",
    "# ============================\n",
    "# 2) 画像前処理\n",
    "# ============================\n",
    "image_size = 384  # 改善点(2): 解像度UP\n",
    "\n",
    "def crop_image(image, x, y, tol=0.05, crop=True):\n",
    "    img = image[0, :, :, 0]\n",
    "    mask = img > tol\n",
    "    if crop and mask.sum() > 1000:\n",
    "        masked_idx = np.ix_(mask.any(1), mask.any(0))\n",
    "        image = img[masked_idx]\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], 1)\n",
    "    if crop and x >= 0 and mask.sum() > 1000:\n",
    "        coor = np.zeros((img.shape), dtype=float)\n",
    "        coor[round(y), round(x)] = 1\n",
    "        coor_masked = coor[masked_idx]\n",
    "        row, col = np.where(coor_masked == 1)\n",
    "        y, x = row[0], col[0]\n",
    "    return image, x, y\n",
    "\n",
    "def pad_and_resize(image, x, y):\n",
    "    _, h, w, _ = image.shape\n",
    "    pad_size = max(h, w)\n",
    "    image_padded = tf.image.resize_with_crop_or_pad(image, pad_size, pad_size)\n",
    "    image_resized = tf.image.resize(image_padded, [image_size, image_size], method=tf.image.ResizeMethod.BICUBIC)\n",
    "    if x >= 0:\n",
    "        coor = np.zeros((image.shape), dtype=float)\n",
    "        coor[:, round(y), round(x), :] = 1\n",
    "        coor_padded = tf.image.resize_with_crop_or_pad(coor, pad_size, pad_size)\n",
    "        coor_resized = tf.image.resize(coor_padded, [image_size, image_size], method=tf.image.ResizeMethod.AREA)\n",
    "        _, row, col, _ = np.where(coor_resized.numpy() == coor_resized.numpy().max())\n",
    "        y, x = row[0], col[0]\n",
    "    return image_resized, x, y\n",
    "\n",
    "def image_augmentation(image, x, y, augmentation=True):\n",
    "    if augmentation:\n",
    "        coor = np.zeros((image.shape), dtype=float)\n",
    "        zoom_fac = np.random.uniform(0.0, 0.0)\n",
    "        rot_fac = np.random.uniform(-0.1, 0.1)\n",
    "        trans_fac = np.random.uniform(-0.05, 0.05)\n",
    "        z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(image)\n",
    "        z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n",
    "        image = tf.keras.layers.RandomTranslation(\n",
    "            height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n",
    "            interpolation='nearest', fill_mode='constant', name='auglay3'\n",
    "        )(z)\n",
    "        if x >= 0:\n",
    "            coor[:, round(y), round(x), :] = 1\n",
    "            coor = tf.convert_to_tensor(coor)\n",
    "            z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(coor)\n",
    "            z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n",
    "            coor = tf.keras.layers.RandomTranslation(\n",
    "                height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n",
    "                interpolation='nearest', fill_mode='constant', name='auglay3'\n",
    "            )(z)\n",
    "            _, row, col, _ = np.where(coor.numpy() == coor.numpy().max())\n",
    "            y, x = row[0], col[0]\n",
    "    return image, x, y\n",
    "\n",
    "def preprocess_images(image, x, y, crop, augmentation):\n",
    "    image_scaled = (MinMaxScaler().fit_transform(image.reshape(-1, 1))).reshape(1, image.shape[0], image.shape[1], 1).astype(np.float32)\n",
    "    try:\n",
    "        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=crop)\n",
    "    except Exception:\n",
    "        image_c, x_c, y_c = crop_image(image_scaled, x, y, crop=False)\n",
    "    image_aug, x_a, y_a = image_augmentation(image_c, x_c, y_c, augmentation=augmentation)\n",
    "    image_resized, x_r, y_r = pad_and_resize(image_aug, x_a, y_a)\n",
    "    image_resized = tf.cast(image_resized*255, dtype=tf.uint8)\n",
    "    if x >= 0:\n",
    "        x_rs, y_rs = x_r/image_size, y_r/image_size\n",
    "    else:\n",
    "        x_rs, y_rs = -1, -1\n",
    "    return image_resized, x_rs, y_rs\n",
    "\n",
    "# ============================\n",
    "# 3) データセット作成\n",
    "# ============================\n",
    "iteration_nr = 4\n",
    "root_path = os.path.join(path, 'series')\n",
    "encoder_mod = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit([['MR'], ['CT']])\n",
    "\n",
    "def preprocess_step(data, iter_nr):\n",
    "    image_list, modality_list, label_list, coordinates_list = [], [], [], []\n",
    "    for i, idx in enumerate(tqdm(data.index)):\n",
    "        data_slice = data.loc[idx]\n",
    "        subfolder = data_slice['SeriesInstanceUID']\n",
    "        subfolder_path = os.path.join(root_path, subfolder)\n",
    "\n",
    "        files_in = os.listdir(subfolder_path)\n",
    "        files_in.sort()\n",
    "        if len(files_in) > iter_nr:\n",
    "            file_name = files_in[iter_nr]\n",
    "        else:\n",
    "            file_name = files_in[-1]\n",
    "        if not pd.isna(data_slice.get('SOPInstanceUID')):\n",
    "            file_name = f\"{data_slice['SOPInstanceUID']}.dcm\"\n",
    "\n",
    "        dcm = pydicom.dcmread(os.path.join(subfolder_path, file_name))\n",
    "        try:\n",
    "            nr_frames = int(dcm.NumberOfFrames)\n",
    "            if data_slice['Aneurysm Present'] == 1:\n",
    "                frame_nr = int(eval(data_slice['coordinates'])['f'])\n",
    "            else:\n",
    "                frame_nr = min(iter_nr, nr_frames-1)\n",
    "        except Exception:\n",
    "            frame_nr = 0\n",
    "\n",
    "        # フレーム取得\n",
    "        img = getattr(pydicom, 'pixels', None)\n",
    "        if img and hasattr(pydicom, 'pixels'):\n",
    "            image = pydicom.pixels.pixel_array(dcm, index=frame_nr)\n",
    "        else:\n",
    "            image = dcm.pixel_array\n",
    "\n",
    "        mod = encoder_mod.transform([[dcm.Modality]])\n",
    "        if pd.isna(data_slice.get('coordinates')):\n",
    "            x, y = -1, -1\n",
    "        else:\n",
    "            xy = eval(data_slice['coordinates'])\n",
    "            x, y = xy['x'], xy['y']\n",
    "\n",
    "        image_resized, x_rs, y_rs = preprocess_images(\n",
    "            image, x, y, crop=False, augmentation=(iter_nr > 0 and data_slice['Aneurysm Present'] == 1)\n",
    "        )\n",
    "        coordinates_tensor = tf.expand_dims(tf.convert_to_tensor([x_rs, y_rs], dtype=np.float32), 0)\n",
    "        image_list.append(image_resized)\n",
    "        modality_list.append(mod)\n",
    "        coordinates_list.append(coordinates_tensor)\n",
    "\n",
    "        labels = data_slice[label_columns]\n",
    "        label_tensor = tf.expand_dims(tf.convert_to_tensor(labels, dtype=np.float32), 0)\n",
    "        label_list.append(label_tensor)\n",
    "\n",
    "    images = tf.concat(image_list, axis=0)\n",
    "    modalities = tf.concat(modality_list, axis=0)\n",
    "    labels = tf.concat(label_list, axis=0)\n",
    "    coordinates = tf.concat(coordinates_list, axis=0)\n",
    "    return images, labels, coordinates, modalities\n",
    "\n",
    "def preprocess_loop(data, iteration_nr):\n",
    "    data_images_list, data_modalities_list, data_labels_list, data_coordinates_list = [], [], [], []\n",
    "    for i in range(iter_nr := iteration_nr):\n",
    "        di, dl, dc, dm = preprocess_step(data, i)\n",
    "        data_images_list.append(di)\n",
    "        data_modalities_list.append(dm)\n",
    "        data_labels_list.append(dl)\n",
    "        data_coordinates_list.append(dc)\n",
    "    data_images = tf.concat(data_images_list, axis=0)\n",
    "    data_modalities = tf.concat(data_modalities_list, axis=0)\n",
    "    data_labels = tf.concat(data_labels_list, axis=0)\n",
    "    data_coordinates = tf.concat(data_coordinates_list, axis=0)\n",
    "    return data_images, data_labels, data_coordinates, data_modalities\n",
    "\n",
    "if not SUBMISSIONING:\n",
    "    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:], iteration_nr)\n",
    "    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:], iteration_nr)\n",
    "else:\n",
    "    train_images, train_labels, train_coordinates, train_modalities = preprocess_loop(train[:64], iteration_nr)\n",
    "    val_images,   val_labels,   val_coordinates,   val_modalities   = preprocess_loop(val[:64], iteration_nr)\n",
    "\n",
    "SEED = 42\n",
    "batch_size = 32 if image_size >= 384 else 64\n",
    "batch_size_val = batch_size\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_img\": train_images, \"input_mod\": train_modalities},\n",
    "     {\"class\": train_labels, \"reg\": train_coordinates})\n",
    ").shuffle(len(train_labels), seed=SEED).repeat().batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"input_img\": val_images, \"input_mod\": val_modalities},\n",
    "     {\"class\": val_labels, \"reg\": val_coordinates})\n",
    ").batch(batch_size_val, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ============================\n",
    "# 4) モデル定義\n",
    "# ============================\n",
    "label_weights = tf.constant([1,1,1,1,1,1,1,1,1,1,1,1,1,13], dtype=tf.float32)/26\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class WeightedBinaryCrossentropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"weighted_bce_loss\", reduction='sum_over_batch_size'):\n",
    "        super().__init__(name=name, reduction=reduction)\n",
    "        self.weight_positive = 1 - tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n",
    "        self.weight_negative = tf.reduce_sum(train_labels, axis=0)/len(train_labels)\n",
    "        self.label_weights = label_weights\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        bce = -(self.weight_positive * y_true * tf.math.log(y_pred) +\n",
    "                self.weight_negative * (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "        bce = bce * self.label_weights\n",
    "        return tf.reduce_mean(bce)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class LearnableRGB(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs): super().__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(3, 1, use_bias=False, name=\"rgb_1x1\")\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, tf.float32)/255.0\n",
    "        return self.conv(x)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PreProcess(tf.keras.layers.Layer):\n",
    "    def __init__(self, base_network_type, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if base_network_type < 9:\n",
    "            self.preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "        else:\n",
    "            self.preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "    def call(self, inputs):\n",
    "        x = tf.cast(inputs, tf.float32)\n",
    "        return self.preprocess_input(x*255.0)\n",
    "\n",
    "def _build_base_model(image_size, base_network_type=9):\n",
    "    # オフライン安全: まずローカル重み→ImageNet許可→Noneの順\n",
    "    weights_arg = 'imagenet' if USE_IMAGENET else None\n",
    "    def _make(weights):\n",
    "        return tf.keras.applications.EfficientNetV2B0(\n",
    "            include_top=False, input_shape=[image_size, image_size, 3], weights=weights\n",
    "        )\n",
    "    try:\n",
    "        if LOCAL_WEIGHTS and os.path.exists(LOCAL_WEIGHTS):\n",
    "            print(f\"Loading base model w/ local weights: {LOCAL_WEIGHTS}\")\n",
    "            m = _make(None)\n",
    "            m.load_weights(LOCAL_WEIGHTS, by_name=True, skip_mismatch=True)\n",
    "            return m\n",
    "        else:\n",
    "            try:\n",
    "                m = _make(weights_arg)  # ここでDLが必要なら、USE_IMAGENET=Falseで回避\n",
    "                return m\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Pretrained weights not available ({e}). Using random init.\")\n",
    "                return _make(None)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Base model fallback to random init ({e}).\")\n",
    "        return _make(None)\n",
    "\n",
    "def build_network(hp):\n",
    "    base_network_type = 9  # EfficientNetV2B0\n",
    "    base_model = _build_base_model(image_size, base_network_type)\n",
    "    preprocessing = PreProcess(base_network_type=base_network_type, name='preprocessing')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # 入力\n",
    "    input_img = tf.keras.Input(shape=(image_size, image_size, 1), name='input_img')\n",
    "    input_mod = tf.keras.Input(shape=(2,), name='input_mod')\n",
    "\n",
    "    # 前処理・ベース\n",
    "    x = LearnableRGB(name='learnable_rgb')(input_img)\n",
    "    x = preprocessing(x)\n",
    "    x = base_model(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='gap2d')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='gap2d_bn')(x)\n",
    "    x = tf.keras.layers.Dropout(0.1, name='gap2d_do')(x)\n",
    "\n",
    "    # モダリティ結合\n",
    "    x = tf.keras.layers.Concatenate(name='concat_gap')([x, input_mod])\n",
    "\n",
    "    # 分類ヘッド\n",
    "    y = tf.keras.layers.Dense(512, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc1')(x)\n",
    "    y = tf.keras.layers.BatchNormalization(name='final_bn1')(y)\n",
    "    y = tf.keras.layers.Dropout(0.1, name='final_do1')(y)\n",
    "    output_lab = tf.keras.layers.Dense(len(label2class.keys()), activation=\"sigmoid\", name='class', dtype='float32')(y)\n",
    "\n",
    "    # 回帰ヘッド\n",
    "    z = tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='he_uniform', name='final_fc_reg1')(x)\n",
    "    z = tf.keras.layers.Dropout(0.1, name='final_do_reg1')(z)\n",
    "    output_coord = tf.keras.layers.Dense(2, activation=\"linear\", name='reg', dtype='float32')(z)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_img, input_mod], outputs=[output_lab, output_coord], name='RSNA_Class')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    loss_class = WeightedBinaryCrossentropy()\n",
    "    loss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\n",
    "    loss_weights = {\"reg\": 0.01, \"class\": 0.99}\n",
    "    auc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='auc')\n",
    "    metrics = {\"reg\": [\"mae\"], \"class\": [auc]}\n",
    "    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n",
    "    return model\n",
    "\n",
    "# ============================\n",
    "# 5) LR: Cosine+Warmup / EMA\n",
    "# ============================\n",
    "warmup_epochs = 5\n",
    "total_epochs  = 100\n",
    "base_lr = 1e-3\n",
    "min_lr  = 1e-5\n",
    "\n",
    "def cosine_warmup_lr(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return base_lr * (epoch + 1) / warmup_epochs\n",
    "    t = (epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n",
    "    return float(min_lr + 0.5*(base_lr - min_lr)*(1 + math.cos(math.pi*t)))\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(cosine_warmup_lr, verbose=0)\n",
    "\n",
    "class EMAWeights(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.shadow = [w.numpy() for w in model.weights]\n",
    "        self.model_ref = model\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        for i, w in enumerate(self.model_ref.weights):\n",
    "            self.shadow[i] = self.decay*self.shadow[i] + (1.0 - self.decay)*w.numpy()\n",
    "    def on_train_end(self, logs=None):\n",
    "        for var, swa in zip(self.model_ref.weights, self.shadow):\n",
    "            var.assign(swa)\n",
    "\n",
    "# ============================\n",
    "# 6) モデルのロード/ビルド\n",
    "# ============================\n",
    "def load_or_build_model():\n",
    "    custom = {\n",
    "        \"WeightedBinaryCrossentropy\": WeightedBinaryCrossentropy,\n",
    "        \"LearnableRGB\": LearnableRGB,\n",
    "        \"PreProcess\": PreProcess,\n",
    "    }\n",
    "    # 1) /kaggle/working を優先\n",
    "    if os.path.exists(MODEL_PATH_WORK):\n",
    "        try:\n",
    "            m = tf.keras.models.load_model(MODEL_PATH_WORK, custom_objects=custom, compile=False)\n",
    "            print(f\"Loaded model from WORKING: {MODEL_PATH_WORK}\")\n",
    "            return m\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load WORKING model: {e}\")\n",
    "    # 2) 次に /kaggle/input\n",
    "    if os.path.exists(MODEL_PATH_INPUT):\n",
    "        try:\n",
    "            m = tf.keras.models.load_model(MODEL_PATH_INPUT, custom_objects=custom, compile=False)\n",
    "            print(f\"Loaded model from INPUT: {MODEL_PATH_INPUT}\")\n",
    "            return m\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load INPUT model: {e}\")\n",
    "    # 3) 無ければ新規構築\n",
    "    print(\"No saved model found. Building a fresh model.\")\n",
    "    with strategy.scope():\n",
    "        return build_network(kt.HyperParameters())\n",
    "\n",
    "model = load_or_build_model()\n",
    "\n",
    "# 再コンパイル（load_model時は compile=False のため）\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "loss_class = WeightedBinaryCrossentropy()\n",
    "loss = {\"reg\": \"mean_squared_error\", \"class\": loss_class}\n",
    "loss_weights = {\"reg\": 0.01, \"class\": 0.99}\n",
    "auc = tf.keras.metrics.AUC(multi_label=True, label_weights=label_weights, name='auc')\n",
    "metrics = {\"reg\": [\"mae\"], \"class\": [auc]}\n",
    "model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights, metrics=metrics, run_eagerly=False)\n",
    "\n",
    "# ============================\n",
    "# 7) 学習\n",
    "# ============================\n",
    "epochs = total_epochs\n",
    "steps_per_epoch = max(1, len(train)//batch_size)\n",
    "TRAINING = (not SUBMISSIONING)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=15, monitor='val_class_auc', mode='max', restore_best_weights=True\n",
    ")\n",
    "ema_cb = EMAWeights(model, decay=0.999)\n",
    "\n",
    "if TRAINING:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[lr_cb, early_stopping_cb, ema_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    # /kaggle/working に保存（ご要望どおり）\n",
    "    model.save(MODEL_PATH_WORK, include_optimizer=False)\n",
    "    print(f\"Model weights have been saved to: {MODEL_PATH_WORK}\")\n",
    "\n",
    "# ============================\n",
    "# 8) しきい値最適化（任意）\n",
    "# ============================\n",
    "THRESH_FILE = os.path.join(MODEL_DIR_WORK, 'class_thresholds.npy')\n",
    "APPLY_THRESHOLDS = False  # 競技が確率提出なら False のまま\n",
    "\n",
    "def compute_optimal_thresholds(model, val_images, val_modalities, val_labels, num_points=201):\n",
    "    probs, _ = model.predict((val_images, val_modalities), verbose=0)\n",
    "    probs = np.asarray(probs)  # (N, C)\n",
    "    labels = np.asarray(val_labels)  # (N, C)\n",
    "    C = probs.shape[1]\n",
    "    thresholds = np.zeros(C, dtype=np.float32)\n",
    "    grid = np.linspace(0.0, 1.0, num_points)\n",
    "    for c in range(C):\n",
    "        y_true = labels[:, c].astype(np.float32)\n",
    "        p = probs[:, c].astype(np.float32)\n",
    "        pos = np.sum(y_true == 1)\n",
    "        neg = np.sum(y_true == 0)\n",
    "        if pos == 0 or neg == 0:\n",
    "            thresholds[c] = 0.5\n",
    "            continue\n",
    "        best_t, best_j = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            yhat = (p >= t).astype(np.float32)\n",
    "            tp = np.sum((yhat == 1) & (y_true == 1))\n",
    "            fp = np.sum((yhat == 1) & (y_true == 0))\n",
    "            fn = np.sum((yhat == 0) & (y_true == 1))\n",
    "            tn = np.sum((yhat == 0) & (y_true == 0))\n",
    "            tpr = tp / (tp + fn + 1e-9)\n",
    "            fpr = fp / (fp + tn + 1e-9)\n",
    "            j = tpr - fpr\n",
    "            if j > best_j:\n",
    "                best_j = j\n",
    "                best_t = t\n",
    "        thresholds[c] = best_t\n",
    "    return thresholds\n",
    "\n",
    "if TRAINING:\n",
    "    thresholds = compute_optimal_thresholds(model, val_images, val_modalities, val_labels)\n",
    "    np.save(THRESH_FILE, thresholds)\n",
    "    print(\"Saved class-wise thresholds to:\", THRESH_FILE)\n",
    "else:\n",
    "    thresholds = np.load(THRESH_FILE) if os.path.exists(THRESH_FILE) else np.full((len(label_columns),), 0.5, dtype=np.float32)\n",
    "\n",
    "# ============================\n",
    "# 9) 推論（シリーズ集約 + しきい値適用オプション）\n",
    "# ============================\n",
    "ID_COL = 'SeriesInstanceUID'\n",
    "LABEL_COLS = list(label_columns)\n",
    "\n",
    "def aggregate_series_probs(frame_probs, k=None):\n",
    "    frame_probs = np.asarray(frame_probs)  # (T, C)\n",
    "    if k is None or k <= 1 or k > frame_probs.shape[0]:\n",
    "        return frame_probs.max(axis=0)\n",
    "    idx = np.argsort(frame_probs, axis=0)[-k:]\n",
    "    topk = np.take_along_axis(frame_probs, idx, axis=0)\n",
    "    return topk.mean(axis=0)\n",
    "\n",
    "def predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n",
    "    series_id = os.path.basename(series_path)\n",
    "    all_filepaths = []\n",
    "    for root, _, files in os.walk(series_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                all_filepaths.append(os.path.join(root, file))\n",
    "    all_filepaths.sort()\n",
    "\n",
    "    image_list, mod_list = [], []\n",
    "    for image_path in all_filepaths:\n",
    "        dcm = pydicom.dcmread(image_path)\n",
    "        image = dcm.pixel_array\n",
    "        mod = encoder_mod.transform([[dcm.Modality]])\n",
    "        if len(image.shape) == 3:  # multiframe\n",
    "            for frame in image:\n",
    "                image_resized, _, _ = preprocess_images(frame, -1, -1, crop=False, augmentation=False)\n",
    "                image_list.append(tf.cast(image_resized, tf.float32))\n",
    "                mod_list.append(tf.cast(mod, tf.float32))\n",
    "        else:  # single frame\n",
    "            image_resized, _, _ = preprocess_images(image, -1, -1, crop=False, augmentation=False)\n",
    "            image_list.append(tf.cast(image_resized, tf.float32))\n",
    "            mod_list.append(tf.cast(mod, tf.float32))\n",
    "\n",
    "    test_images = tf.concat(image_list, axis=0)\n",
    "    test_mods   = tf.concat(mod_list,   axis=0)\n",
    "\n",
    "    lab, _ = model.predict((test_images, test_mods), verbose=0)  # (T, C)\n",
    "    prob_lab = aggregate_series_probs(lab, k=None)  # max集約（必要なら k=3 等に）\n",
    "\n",
    "    if APPLY_THRESHOLDS:\n",
    "        th = thresholds if 'thresholds' in globals() else np.full_like(prob_lab, 0.5)\n",
    "        out_vec = (prob_lab >= th).astype(float).tolist()\n",
    "    else:\n",
    "        out_vec = prob_lab.astype(float).tolist()\n",
    "\n",
    "    predictions = pl.DataFrame(\n",
    "        data=[[series_id] + out_vec],\n",
    "        schema=[ID_COL, *LABEL_COLS], orient='row'\n",
    "    )\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    # 競技が確率提出の場合は APPLY_THRESHOLDS=False を維持してください\n",
    "    return predictions.drop(ID_COL)\n",
    "\n",
    "# ============================\n",
    "# 10) 提出サーバ（SUBMISSIONING=Trueのとき）\n",
    "# ============================\n",
    "if SUBMISSIONING:\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway()\n",
    "        try:\n",
    "            display(pl.read_parquet('/kaggle/working/submission.parquet'))\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff6934",
   "metadata": {
    "papermill": {
     "duration": 0.797968,
     "end_time": "2025-10-10T08:38:21.098935",
     "exception": false,
     "start_time": "2025-10-10T08:38:20.300967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "sourceId": 99552,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4355.587066,
   "end_time": "2025-10-10T08:38:24.811150",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-10T07:25:49.224084",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
